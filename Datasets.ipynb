{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2978067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "from typing import Dict, Set, Optional, Tuple\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc4ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "DJANGO_PROJECT_PATH = \"/Users/ryanmarr/Documents/sentry\"\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "MAX_TOKENS = 2048\n",
    "TEMPERATURE = 0.1\n",
    "TOP_P = 1\n",
    "STREAM = False\n",
    "MAX_TOKENS = 30000\n",
    "PROMPT_TOKENS = 251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14418da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq client setup\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb8c7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens_for_gpt4o(text: str) -> int:\n",
    "    \"\"\"Count tokens for GPT-4o using tiktoken\"\"\"\n",
    "    try:\n",
    "        # Use the cl100k_base encoding which is used by GPT-4o\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        tokens = encoding.encode(text)\n",
    "        return len(tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"Error counting tokens: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa98c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_django_files(directory: str) -> List[str]:\n",
    "    \"\"\"Perform DFS to find all Python files in Django project\"\"\"\n",
    "    django_files = []\n",
    "    priority_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Skip common directories that don't contain Django code\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', 'env', '.git']]\n",
    "        \n",
    "        for file in files:\n",
    "            if file == 'views.py':\n",
    "                priority_files.append(os.path.join(root, file))\n",
    "            elif file.endswith('.py'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                django_files.append(file_path)\n",
    "\n",
    "    return priority_files + django_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0424ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "from typing import Dict, Set, Optional, List, Any\n",
    "\n",
    "def find_function_in_ast(tree: ast.AST, function_name: str) -> Optional[ast.FunctionDef]:\n",
    "    \"\"\"Find a function definition in the AST by name.\"\"\"\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef) and node.name == function_name:\n",
    "            return node\n",
    "    return None\n",
    "\n",
    "def find_class_in_ast(tree: ast.AST, class_name: str) -> Optional[ast.ClassDef]:\n",
    "    \"\"\"Find a class definition in the AST by name.\"\"\"\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.ClassDef) and node.name == class_name:\n",
    "            return node\n",
    "    return None\n",
    "\n",
    "def find_all_imports_in_file(tree: ast.AST, current_file_path: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Find all imports in the entire file, not just within a function.\n",
    "    \n",
    "    Returns:\n",
    "        Dict mapping import names to their file paths\n",
    "    \"\"\"\n",
    "    all_imports = {}\n",
    "    \n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Import):\n",
    "            for alias in node.names:\n",
    "                import_name = alias.asname or alias.name\n",
    "                import_path = resolve_local_import_path(alias.name, current_file_path)\n",
    "                if import_path:\n",
    "                    all_imports[import_name] = import_path\n",
    "                    \n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            if node.module:\n",
    "                import_path = resolve_local_import_path(node.module, current_file_path)\n",
    "                if import_path:\n",
    "                    for alias in node.names:\n",
    "                        import_name = alias.asname or alias.name\n",
    "                        all_imports[import_name] = import_path\n",
    "    \n",
    "    return all_imports\n",
    "\n",
    "def find_local_imports_in_function(function_ast: ast.FunctionDef, current_file_path: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Find all local imports used within a function.\n",
    "    \n",
    "    Returns:\n",
    "        Dict mapping import names to their file paths\n",
    "    \"\"\"\n",
    "    local_imports = {}\n",
    "    \n",
    "    for node in ast.walk(function_ast):\n",
    "        if isinstance(node, ast.Import):\n",
    "            for alias in node.names:\n",
    "                import_name = alias.asname or alias.name\n",
    "                import_path = resolve_local_import_path(alias.name, current_file_path)\n",
    "                if import_path:\n",
    "                    local_imports[import_name] = import_path\n",
    "                    \n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            if node.module:\n",
    "                import_path = resolve_local_import_path(node.module, current_file_path)\n",
    "                if import_path:\n",
    "                    for alias in node.names:\n",
    "                        import_name = alias.asname or alias.name\n",
    "                        local_imports[import_name] = import_path\n",
    "    \n",
    "    return local_imports\n",
    "\n",
    "def resolve_local_import_path(module_name: str, current_file_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Resolve a local import path to an actual file path.\n",
    "    \n",
    "    Args:\n",
    "        module_name (str): The module name from the import statement\n",
    "        current_file_path (str): Path to the current file\n",
    "        \n",
    "    Returns:\n",
    "        Optional[str]: Resolved file path or None if not found\n",
    "    \"\"\"\n",
    "    current_dir = os.path.dirname(current_file_path)\n",
    "    \n",
    "    # Handle relative imports (e.g., from .models import User)\n",
    "    if module_name.startswith('.'):\n",
    "        # Remove the leading dot\n",
    "        relative_path = module_name[1:]\n",
    "        if relative_path:\n",
    "            possible_paths = [\n",
    "                os.path.join(current_dir, f\"{relative_path}.py\"),\n",
    "                os.path.join(current_dir, relative_path, \"__init__.py\"),\n",
    "                os.path.join(current_dir, relative_path, f\"{relative_path}.py\")\n",
    "            ]\n",
    "        else:\n",
    "            # Just a dot means current directory\n",
    "            possible_paths = [\n",
    "                os.path.join(current_dir, \"__init__.py\")\n",
    "            ]\n",
    "    else:\n",
    "        # Absolute imports - try multiple strategies\n",
    "        possible_paths = []\n",
    "        \n",
    "        # Strategy 1: Look in current directory\n",
    "        possible_paths.extend([\n",
    "            os.path.join(current_dir, f\"{module_name}.py\"),\n",
    "            os.path.join(current_dir, module_name, \"__init__.py\"),\n",
    "            os.path.join(current_dir, module_name, f\"{module_name}.py\")\n",
    "        ])\n",
    "        \n",
    "        # Strategy 2: Look in parent directories\n",
    "        parent_dir = current_dir\n",
    "        for _ in range(3):  # Go up to 3 levels\n",
    "            parent_dir = os.path.dirname(parent_dir)\n",
    "            if parent_dir:\n",
    "                possible_paths.extend([\n",
    "                    os.path.join(parent_dir, f\"{module_name}.py\"),\n",
    "                    os.path.join(parent_dir, module_name, \"__init__.py\"),\n",
    "                    os.path.join(parent_dir, module_name, f\"{module_name}.py\")\n",
    "                ])\n",
    "        \n",
    "        # Strategy 3: Handle nested module paths (e.g., dependency_test.b)\n",
    "        if '.' in module_name:\n",
    "            parts = module_name.split('.')\n",
    "            # Try to find the module in various parent directories\n",
    "            for i in range(len(parts)):\n",
    "                module_path = os.path.join(*parts[i:])\n",
    "                possible_paths.extend([\n",
    "                    os.path.join(current_dir, f\"{module_path}.py\"),\n",
    "                    os.path.join(current_dir, module_path, \"__init__.py\")\n",
    "                ])\n",
    "                \n",
    "                # Also try in parent directories\n",
    "                parent_dir = current_dir\n",
    "                for _ in range(3):\n",
    "                    parent_dir = os.path.dirname(parent_dir)\n",
    "                    if parent_dir:\n",
    "                        possible_paths.extend([\n",
    "                            os.path.join(parent_dir, f\"{module_path}.py\"),\n",
    "                            os.path.join(parent_dir, module_path, \"__init__.py\")\n",
    "                        ])\n",
    "    \n",
    "    # Try to find the file\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    \n",
    "    return None\n",
    "\n",
    "def expand_imported_file_recursively(import_path: str, import_name: str, visited_files: Set[str], max_depth: int) -> str:\n",
    "    \"\"\"\n",
    "    Recursively expand an imported file, showing all its functions and their dependencies.\n",
    "    \n",
    "    Args:\n",
    "        import_path (str): Path to the imported file\n",
    "        import_name (str): Name of the imported module\n",
    "        visited_files (Set[str]): Set of visited files to prevent circular imports\n",
    "        max_depth (int): Maximum recursion depth\n",
    "        \n",
    "    Returns:\n",
    "        str: Recursively expanded content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(import_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        tree = ast.parse(content)\n",
    "        \n",
    "        # Find all functions and classes in this file\n",
    "        functions = []\n",
    "        classes = []\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                functions.append(node)\n",
    "            elif isinstance(node, ast.ClassDef):\n",
    "                classes.append(node)\n",
    "        \n",
    "        result = f\"# File: {import_path}\\n\"\n",
    "        result += f\"# Module: {import_name}\\n\"\n",
    "        result += \"-\" * 60 + \"\\n\\n\"\n",
    "        \n",
    "        # Show classes first\n",
    "        if classes:\n",
    "            result += \"# CLASSES:\\n\"\n",
    "            for class_node in classes:\n",
    "                result += f\"# Class: {class_node.name}\\n\"\n",
    "                result += ast.unparse(class_node) + \"\\n\\n\"\n",
    "        \n",
    "        # Show functions and recursively expand their imports\n",
    "        if functions:\n",
    "            result += \"# FUNCTIONS:\\n\"\n",
    "            for func_node in functions:\n",
    "                func_name = func_node.name\n",
    "                result += f\"# Function: {func_name}\\n\"\n",
    "                result += ast.unparse(func_node) + \"\\n\\n\"\n",
    "                \n",
    "                # Recursively expand this function's imports\n",
    "                if max_depth > 0:\n",
    "                    func_imports = find_local_imports_in_function(func_node, import_path)\n",
    "                    if func_imports:\n",
    "                        result += f\"# Dependencies of {func_name}:\\n\"\n",
    "                        for dep_name, dep_path in func_imports.items():\n",
    "                            if os.path.exists(dep_path) and dep_path not in visited_files:\n",
    "                                # Recursively expand this dependency\n",
    "                                dep_content = expand_imported_file_recursively(\n",
    "                                    dep_path, dep_name, visited_files.copy(), max_depth - 1\n",
    "                                )\n",
    "                                result += f\"# From {dep_name}:\\n\"\n",
    "                                result += dep_content + \"\\n\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"# Error reading {import_path}: {str(e)}\"\n",
    "\n",
    "def expand_function_with_imports_recursive(file_path: str, function_name: str, visited_files: Set[str] = None, max_depth: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Recursively expand a function from a Django file, resolving ALL local imports\n",
    "    recursively to show the complete implementation chain.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Django file\n",
    "        function_name (str): Name of the function to expand\n",
    "        visited_files (Set[str]): Set of already visited files to prevent circular imports\n",
    "        max_depth (int): Maximum recursion depth to prevent infinite loops\n",
    "        \n",
    "    Returns:\n",
    "        str: Complete expanded function implementation with all imports recursively resolved\n",
    "    \"\"\"\n",
    "    if visited_files is None:\n",
    "        visited_files = set()\n",
    "    \n",
    "    # Prevent circular imports and excessive recursion\n",
    "    if file_path in visited_files or max_depth <= 0:\n",
    "        return f\"# Circular import or max depth reached: {file_path}\"\n",
    "    \n",
    "    visited_files.add(file_path)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Parse the Python file\n",
    "        tree = ast.parse(content)\n",
    "        \n",
    "        # Find the target function\n",
    "        function_ast = find_function_in_ast(tree, function_name)\n",
    "        if not function_ast:\n",
    "            return f\"# Function '{function_name}' not found in {file_path}\"\n",
    "        \n",
    "        # Get the function's source code\n",
    "        function_source = ast.unparse(function_ast)\n",
    "        \n",
    "        # Find all imports in the file\n",
    "        file_imports = find_all_imports_in_file(tree, file_path)\n",
    "        \n",
    "        # Find all local imports used within the function\n",
    "        function_imports = find_local_imports_in_function(function_ast, file_path)\n",
    "        \n",
    "        # Combine all imports\n",
    "        all_imports = {**file_imports, **function_imports}\n",
    "        \n",
    "        # Recursively expand each local import\n",
    "        expanded_imports = {}\n",
    "        for import_name, import_path in all_imports.items():\n",
    "            if os.path.exists(import_path):\n",
    "                # Recursively expand this imported file\n",
    "                expanded_content = expand_imported_file_recursively(\n",
    "                    import_path, import_name, visited_files.copy(), max_depth - 1\n",
    "                )\n",
    "                expanded_imports[import_name] = expanded_content\n",
    "        \n",
    "        # Build the complete expanded function\n",
    "        result = f\"# Function: {function_name}\\n\"\n",
    "        result += f\"# File: {file_path}\\n\"\n",
    "        result += \"=\" * 80 + \"\\n\\n\"\n",
    "        \n",
    "        # Add expanded imports first\n",
    "        if expanded_imports:\n",
    "            result += \"# RECURSIVELY EXPANDED IMPORTS:\\n\"\n",
    "            result += \"-\" * 40 + \"\\n\"\n",
    "            for import_name, import_content in expanded_imports.items():\n",
    "                result += f\"# From: {import_name}\\n\"\n",
    "                result += import_content + \"\\n\\n\"\n",
    "        \n",
    "        # Add the main function\n",
    "        result += \"# MAIN FUNCTION IMPLEMENTATION:\\n\"\n",
    "        result += \"-\" * 40 + \"\\n\"\n",
    "        result += function_source\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"# Error processing {file_path}: {str(e)}\"\n",
    "\n",
    "# Helper function to find all function calls in a function\n",
    "def find_function_calls_in_function(function_ast: ast.FunctionDef) -> List[str]:\n",
    "    \"\"\"Find all function calls made within a function.\"\"\"\n",
    "    function_calls = []\n",
    "    \n",
    "    for node in ast.walk(function_ast):\n",
    "        if isinstance(node, ast.Call):\n",
    "            if isinstance(node.func, ast.Name):\n",
    "                function_calls.append(node.func.id)\n",
    "            elif isinstance(node.func, ast.Attribute):\n",
    "                function_calls.append(node.func.attr)\n",
    "    \n",
    "    return function_calls\n",
    "\n",
    "# Alternative version that shows the complete call chain\n",
    "def expand_function_with_call_chain(file_path: str, function_name: str, visited_files: Set[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Expand a function and show the complete call chain recursively.\n",
    "    \"\"\"\n",
    "    if visited_files is None:\n",
    "        visited_files = set()\n",
    "    \n",
    "    if file_path in visited_files:\n",
    "        return f\"# Circular import detected: {file_path}\"\n",
    "    \n",
    "    visited_files.add(file_path)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        tree = ast.parse(content)\n",
    "        function_ast = find_function_in_ast(tree, function_name)\n",
    "        \n",
    "        if not function_ast:\n",
    "            return f\"# Function '{function_name}' not found in {file_path}\"\n",
    "        \n",
    "        # Get the function source\n",
    "        function_source = ast.unparse(function_ast)\n",
    "        \n",
    "        # Find function calls in this function\n",
    "        function_calls = find_function_calls_in_function(function_ast)\n",
    "        \n",
    "        result = f\"# Function: {function_name}\\n\"\n",
    "        result += f\"# File: {file_path}\\n\"\n",
    "        result += \"=\" * 80 + \"\\n\\n\"\n",
    "        \n",
    "        result += \"# MAIN FUNCTION:\\n\"\n",
    "        result += \"-\" * 40 + \"\\n\"\n",
    "        result += function_source + \"\\n\\n\"\n",
    "        \n",
    "        # Recursively expand each function call\n",
    "        if function_calls:\n",
    "            result += \"# FUNCTION CALL CHAIN:\\n\"\n",
    "            result += \"-\" * 40 + \"\\n\"\n",
    "            \n",
    "            for call_name in function_calls:\n",
    "                # Try to find this function in the current file or imported files\n",
    "                import_path = resolve_local_import_path(call_name, file_path)\n",
    "                if import_path and os.path.exists(import_path):\n",
    "                    result += f\"# Expanding call to: {call_name}\\n\"\n",
    "                    call_content = expand_function_with_call_chain(import_path, call_name, visited_files.copy())\n",
    "                    result += call_content + \"\\n\\n\"\n",
    "                else:\n",
    "                    result += f\"# Could not resolve: {call_name}\\n\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"# Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4e3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_file_to_string(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Read a Python file and return its contents as a string.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Python file\n",
    "        \n",
    "    Returns:\n",
    "        str: Contents of the file as a string, or empty string if error occurs\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the file doesn't exist\n",
    "        UnicodeDecodeError: If the file can't be decoded as UTF-8\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found\")\n",
    "        return \"\"\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error: Unable to decode file '{file_path}' as UTF-8: {e}\")\n",
    "        return \"\"\n",
    "    except PermissionError:\n",
    "        print(f\"Error: Permission denied reading file '{file_path}'\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error reading file '{file_path}': {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "384c6e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: # Function: a\n",
      "# File: /Users/ryanmarr/Documents/duct_env/duct/dependency_test/a.py\n",
      "================================================================================\n",
      "\n",
      "# RECURSIVELY EXPANDED IMPORTS:\n",
      "----------------------------------------\n",
      "# From: b\n",
      "# File: /Users/ryanmarr/Documents/duct_env/duct/dependency_test/b.py\n",
      "# Module: b\n",
      "------------------------------------------------------------\n",
      "\n",
      "# FUNCTIONS:\n",
      "# Function: b\n",
      "def b():\n",
      "    return 'b' + c()\n",
      "\n",
      "\n",
      "\n",
      "# MAIN FUNCTION IMPLEMENTATION:\n",
      "----------------------------------------\n",
      "def a():\n",
      "    return 'a' + b()\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/ryanmarr/Documents/duct_env/duct/dependency_test/a.py'\n",
    "content = expand_function_with_imports_recursive(file_path, \"a\")\n",
    "print(f'content: {content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50661143",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43masdfs\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdfs' is not defined"
     ]
    }
   ],
   "source": [
    "asdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae22688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rest_apis_from_file_with_openai(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Use OpenAI to analyze file content and find REST APIs\"\"\"\n",
    "    try:\n",
    "\n",
    "        if file_path.endswith('.py'):\n",
    "            content = python_file_to_string(file_path)\n",
    "\n",
    "        # Skip files that don't contain common Django/API keywords\n",
    "        # if not any(keyword in content.lower() for keyword in ['api', 'view', 'rest', 'http', 'request', 'response', 'serializer']):\n",
    "        #     return []\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Analyze this Python file and identify all Django REST API functions or classes. Only return the functions that are REST API endpoints. \n",
    "        Only return entire implemenation of the function including function signature and content. \n",
    "        \n",
    "        Look for:\n",
    "        1. Functions that handle HTTP methods (GET, POST, PUT, DELETE, PATCH)\n",
    "        2. Functions that process requests and return responses\n",
    "        3. Any other REST API endpoints\n",
    "        \n",
    "        File content:\n",
    "        {content}\n",
    "        \n",
    "        IMPORTANT: Return ONLY valid JSON with this exact structure:\n",
    "        {{\n",
    "            \"apis\": [\n",
    "                {{\n",
    "                    \"name\": \"function_or_class_name\",\n",
    "                    \"http_method\": \"GET|POST|PUT|DELETE|PATCH|UNKNOWN\",\n",
    "                    \"description\": \"Brief description of what this API does\",\n",
    "                    \"content_django\": actual function and entire implementation funtion include function signature and content,\n",
    "                    \"content_dafny\": Based on the django function, create a Dafny function specification with preconditions and postconditions assume db schema exists as a dafny type\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \n",
    "        If no REST APIs are found, return: {{\"apis\": []}}\n",
    "        Do not include any text before or after the JSON.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                temperature=TEMPERATURE,\n",
    "                max_tokens=MAX_TOKENS,\n",
    "                top_p=TOP_P,\n",
    "                stream=STREAM\n",
    "            )\n",
    "            \n",
    "            response = completion.choices[0].message.content.strip()\n",
    "            \n",
    "            # Improved JSON extraction\n",
    "            try:\n",
    "                # First, try to parse the entire response as JSON\n",
    "                result = json.loads(response)\n",
    "                if 'apis' in result:\n",
    "                    for api in result.get('apis', []):\n",
    "                        api['file_path'] = file_path\n",
    "                    return result.get('apis', [])\n",
    "            except json.JSONDecodeError:\n",
    "                # If that fails, try to find JSON within the response\n",
    "                # Look for content between the first { and last }\n",
    "                start = response.find('{')\n",
    "                end = response.rfind('}')\n",
    "                \n",
    "                if start != -1 and end != -1 and end > start:\n",
    "                    json_str = response[start:end + 1]\n",
    "                    try:\n",
    "                        result = json.loads(json_str)\n",
    "                        if 'apis' in result:\n",
    "                            for api in result.get('apis', []):\n",
    "                                api['file_path'] = file_path\n",
    "                            return result.get('apis', [])\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Failed to parse extracted JSON from response for {file_path}\")\n",
    "                        print(f\"Extracted JSON string: {json_str}\")\n",
    "                        return []\n",
    "                else:\n",
    "                    print(f\"No JSON structure found in response for {file_path}\")\n",
    "                    print(f\"Response: {response}\")\n",
    "                    return []\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling OpenAI API for {file_path}: {e}\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e504891",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Analyze Django project and generate Dafny specifications\"\"\"\n",
    "\n",
    "# Find all Python files\n",
    "django_files = find_django_files(DJANGO_PROJECT_PATH)\n",
    "print(f\"Found {len(django_files)} Python files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc187fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#django_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract REST APIs using OpenAI\n",
    "all_apis = []\n",
    "for file_path in tqdm(django_files, desc=\"Analyzing files\"):\n",
    "    apis = extract_rest_apis_from_file_with_openai(file_path)\n",
    "    # print(f'apis: {apis}')\n",
    "    all_apis.extend(apis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249bbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_full_api_info(apis: List[Dict[str, Any]]):\n",
    "    \"\"\"Display complete API information with full Django code and Dafny specs\"\"\"\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(\"COMPLETE DJANGO REST API ANALYSIS\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Total APIs found: {len(apis)}\")\n",
    "    print()\n",
    "    \n",
    "    # Group by file path\n",
    "    files = {}\n",
    "    for api in apis:\n",
    "        file_path = api.get('file_path', 'Unknown')\n",
    "        if file_path not in files:\n",
    "            files[file_path] = []\n",
    "        files[file_path].append(api)\n",
    "    \n",
    "    # Display by file\n",
    "    for file_path, file_apis in files.items():\n",
    "        print(f\"📁 FILE: {file_path}\")\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"APIs found: {len(file_apis)}\")\n",
    "        print()\n",
    "        \n",
    "        for i, api in enumerate(file_apis, 1):\n",
    "            print(f\"🔗 API #{i}: {api.get('name', 'Unknown')}\")\n",
    "            print(f\"   Method: {api.get('http_method', 'UNKNOWN')}\")\n",
    "            print(f\"   Description: {api.get('description', 'No description')}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"📝 DJANGO CODE:\")\n",
    "            print(\"-\" * 50)\n",
    "            django_code = api.get('content_django', 'No Django code available')\n",
    "            print(django_code)\n",
    "            print()\n",
    "            \n",
    "            print(\"🔬 DAFNY SPECIFICATION:\")\n",
    "            print(\"-\" * 50)\n",
    "            dafny_spec = api.get('content_dafny', 'No Dafny specification available')\n",
    "            print(dafny_spec)\n",
    "            print()\n",
    "            \n",
    "            print(\"─\" * 100)\n",
    "            print()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"=\" * 100)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # HTTP method distribution\n",
    "    methods = {}\n",
    "    for api in apis:\n",
    "        method = api.get('http_method', 'UNKNOWN')\n",
    "        methods[method] = methods.get(method, 0) + 1\n",
    "    \n",
    "    print(\"HTTP Methods:\")\n",
    "    for method, count in sorted(methods.items()):\n",
    "        print(f\"  {method}: {count}\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Files analyzed: {len(files)}\")\n",
    "    print(f\"Total APIs: {len(apis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23afccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_full_api_info(all_apis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".duct_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
