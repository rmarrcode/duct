{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2978067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "DJANGO_PROJECT_PATH = \"/Users/ryanmarr/Documents/saleor\"\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "MAX_TOKENS = 2048\n",
    "TEMPERATURE = 0.1\n",
    "TOP_P = 1\n",
    "STREAM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14418da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq client setup\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa98c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_django_files(directory: str) -> List[str]:\n",
    "    \"\"\"Perform DFS to find all Python files in Django project\"\"\"\n",
    "    django_files = []\n",
    "    priority_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Skip common directories that don't contain Django code\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', 'env', '.git']]\n",
    "        \n",
    "        for file in files:\n",
    "            if file == 'views.py':\n",
    "                priority_files.append(os.path.join(root, file))\n",
    "            elif file.endswith('.py'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                django_files.append(file_path)\n",
    "\n",
    "    return priority_files + django_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d07a2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_rest_apis_from_file_with_openai(file_path: str) -> List[Dict[str, Any]]:\n",
    "#     \"\"\"Use OpenAI to analyze file content and find REST APIs\"\"\"\n",
    "#     try:\n",
    "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#             content = f.read()  \n",
    "        \n",
    "#         # Skip files that don't contain common Django/API keywords\n",
    "#         if not any(keyword in content.lower() for keyword in ['api', 'view', 'rest', 'http', 'request', 'response', 'serializer']):\n",
    "#             return []\n",
    "\n",
    "#         prompt = f\"\"\"\n",
    "#         Analyze this Python file and identify all Django API functions or classes. Only return the functions that are API endpoints. Only return entire implemenation of the function including function signature and content. \n",
    "        \n",
    "#         File: {file_path}\n",
    "        \n",
    "#         Look for:\n",
    "#         1. Functions that handle HTTP methods (GET, POST, PUT, DELETE, PATCH)\n",
    "#         2. Functions that process requests and return responses\n",
    "        \n",
    "#         File content:\n",
    "#         {content}  \n",
    "        \n",
    "#         IMPORTANT: Return ONLY valid JSON with this exact structure:\n",
    "#         {{\n",
    "#             \"apis\": [\n",
    "#                 {{\n",
    "#                     \"name\": \"function_or_class_name\",\n",
    "#                     \"http_method\": \"GET|POST|PUT|DELETE|PATCH|UNKNOWN\",\n",
    "#                     \"description\": \"Brief description of what this API does\",\n",
    "#                     \"content_django\": actual function and entire implementation funtion include function signature and content,\n",
    "#                     \"content_dafny\": Based on the django function, create a Dafny function specification with preconditions and postconditions assume db schema exists as a dafny type\n",
    "#                 }}\n",
    "#             ]\n",
    "#         }}\n",
    "        \n",
    "#         If no APIs are found, return: {{\"apis\": []}}\n",
    "#         Do not include any text before or after the JSON.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         try:\n",
    "#             completion = client.chat.completions.create(\n",
    "#                 model=MODEL_NAME,\n",
    "#                 messages=[\n",
    "#                     {\n",
    "#                         \"role\": \"user\",\n",
    "#                         \"content\": prompt\n",
    "#                     }\n",
    "#                 ],\n",
    "#                 temperature=TEMPERATURE,\n",
    "#                 max_tokens=MAX_TOKENS,\n",
    "#                 top_p=TOP_P,\n",
    "#                 stream=STREAM\n",
    "#             )\n",
    "            \n",
    "#             response = completion.choices[0].message.content.strip()\n",
    "            \n",
    "#             # Improved JSON extraction\n",
    "#             try:\n",
    "#                 # First, try to parse the entire response as JSON\n",
    "#                 result = json.loads(response)\n",
    "#                 if 'apis' in result:\n",
    "#                     for api in result.get('apis', []):\n",
    "#                         api['file_path'] = file_path\n",
    "#                     return result.get('apis', [])\n",
    "#             except json.JSONDecodeError:\n",
    "#                 # If that fails, try to find JSON within the response\n",
    "#                 # Look for content between the first { and last }\n",
    "#                 start = response.find('{')\n",
    "#                 end = response.rfind('}')\n",
    "                \n",
    "#                 if start != -1 and end != -1 and end > start:\n",
    "#                     json_str = response[start:end + 1]\n",
    "#                     try:\n",
    "#                         result = json.loads(json_str)\n",
    "#                         if 'apis' in result:\n",
    "#                             for api in result.get('apis', []):\n",
    "#                                 api['file_path'] = file_path\n",
    "#                             return result.get('apis', [])\n",
    "#                     except json.JSONDecodeError:\n",
    "#                         print(f\"Failed to parse extracted JSON from response for {file_path}\")\n",
    "#                         print(f\"Extracted JSON string: {json_str}\")\n",
    "#                         return []\n",
    "#                 else:\n",
    "#                     print(f\"No JSON structure found in response for {file_path}\")\n",
    "#                     print(f\"Response: {response}\")\n",
    "#                     return []\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error calling OpenAI API for {file_path}: {e}\")\n",
    "#             return []\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading file {file_path}: {e}\")\n",
    "#         return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae22688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rest_apis_from_file_with_openai(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Use OpenAI to analyze file content and find REST APIs\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()  \n",
    "        \n",
    "        # Skip files that don't contain common Django/API keywords\n",
    "        if not any(keyword in content.lower() for keyword in ['api', 'view', 'rest', 'http', 'request', 'response', 'serializer']):\n",
    "            return []\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Analyze this Python file and identify all Django REST API functions or classes. Only return the functions that are REST API endpoints. Only return entire implemenation of the function including function signature and content. \n",
    "        \n",
    "        File: {file_path}\n",
    "        \n",
    "        Look for:\n",
    "        1. Functions that handle HTTP methods (GET, POST, PUT, DELETE, PATCH)\n",
    "        2. Functions that process requests and return responses\n",
    "        3. Any other REST API endpoints\n",
    "        \n",
    "        File content:\n",
    "        {content}  # First 4000 chars for analysis\n",
    "        \n",
    "        IMPORTANT: Return ONLY valid JSON with this exact structure:\n",
    "        {{\n",
    "            \"apis\": [\n",
    "                {{\n",
    "                    \"name\": \"function_or_class_name\",\n",
    "                    \"http_method\": \"GET|POST|PUT|DELETE|PATCH|UNKNOWN\",\n",
    "                    \"description\": \"Brief description of what this API does\",\n",
    "                    \"content_django\": actual function and entire implementation funtion include function signature and content,\n",
    "                    \"content_dafny\": Based on the django function, create a Dafny function specification with preconditions and postconditions assume db schema exists as a dafny type\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \n",
    "        If no REST APIs are found, return: {{\"apis\": []}}\n",
    "        Do not include any text before or after the JSON.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                temperature=TEMPERATURE,\n",
    "                max_tokens=MAX_TOKENS,\n",
    "                top_p=TOP_P,\n",
    "                stream=STREAM\n",
    "            )\n",
    "            \n",
    "            response = completion.choices[0].message.content.strip()\n",
    "            \n",
    "            # Improved JSON extraction\n",
    "            try:\n",
    "                # First, try to parse the entire response as JSON\n",
    "                result = json.loads(response)\n",
    "                if 'apis' in result:\n",
    "                    for api in result.get('apis', []):\n",
    "                        api['file_path'] = file_path\n",
    "                    return result.get('apis', [])\n",
    "            except json.JSONDecodeError:\n",
    "                # If that fails, try to find JSON within the response\n",
    "                # Look for content between the first { and last }\n",
    "                start = response.find('{')\n",
    "                end = response.rfind('}')\n",
    "                \n",
    "                if start != -1 and end != -1 and end > start:\n",
    "                    json_str = response[start:end + 1]\n",
    "                    try:\n",
    "                        result = json.loads(json_str)\n",
    "                        if 'apis' in result:\n",
    "                            for api in result.get('apis', []):\n",
    "                                api['file_path'] = file_path\n",
    "                            return result.get('apis', [])\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Failed to parse extracted JSON from response for {file_path}\")\n",
    "                        print(f\"Extracted JSON string: {json_str}\")\n",
    "                        return []\n",
    "                else:\n",
    "                    print(f\"No JSON structure found in response for {file_path}\")\n",
    "                    print(f\"Response: {response}\")\n",
    "                    return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error calling OpenAI API for {file_path}: {e}\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3434058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4045 Python files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 1/4045 [00:30<33:56:38, 30.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: [{'name': 'handle_thumbnail', 'http_method': 'UNKNOWN', 'description': 'Create and return thumbnail for given instance in provided size and format.', 'content_django': 'def handle_thumbnail(request, instance_id: str, size: str, format: str | None = None):\\n    \"\"\"Create and return thumbnail for given instance in provided size and format.\\n\\n    If the provided size is not in the available resolution list, the thumbnail with\\n    the closest available size is created and returned, if it does not exist.\\n    \"\"\"\\n    # try to find corresponding instance based on given instance_id\\n    try:\\n        object_type, pk = from_global_id_or_error(instance_id, raise_error=True)\\n    except GraphQLError:\\n        return HttpResponseNotFound(\"Cannot found instance with the given id.\")\\n\\n    if object_type not in TYPE_TO_MODEL_DATA_MAPPING.keys():\\n        return HttpResponseNotFound(\"Invalid instance type.\")\\n\\n    # check formats\\n    format = format.lower() if format else None\\n    if object_type in ICON_TYPE_TO_MODEL_DATA_MAPPING:\\n        if format and format not in ALLOWED_ICON_THUMBNAIL_FORMATS:\\n            return HttpResponseNotFound(\"Unsupported icon image format.\")\\n    elif format and format not in ALLOWED_THUMBNAIL_FORMATS:\\n        return HttpResponseNotFound(\"Unsupported image format.\")\\n\\n    try:\\n        size_px = get_thumbnail_size(int(size))\\n    except ValueError:\\n        return HttpResponseNotFound(\"Invalid size.\")\\n\\n    # return the thumbnail if it\\'s already exist\\n    model_data = TYPE_TO_MODEL_DATA_MAPPING[object_type]\\n    if object_type in UUID_IDENTIFIABLE_TYPES:\\n        instance_id_lookup = model_data.thumbnail_field + \"__uuid\"\\n    else:\\n        instance_id_lookup = model_data.thumbnail_field + \"_id\"\\n\\n    if (\\n        thumbnail := Thumbnail.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME)\\n        .filter(format=format, size=size_px, **{instance_id_lookup: pk})\\n        .first()\\n    ):\\n        return HttpResponseRedirect(thumbnail.image.url)\\n\\n    try:\\n        if object_type in UUID_IDENTIFIABLE_TYPES:\\n            instance = model_data.model.objects.using(\\n                settings.DATABASE_CONNECTION_REPLICA_NAME\\n            ).get(uuid=pk)  # type: ignore[misc]\\n        else:\\n            instance = model_data.model.objects.using(\\n                settings.DATABASE_CONNECTION_REPLICA_NAME\\n            ).get(id=pk)\\n    except ObjectDoesNotExist:\\n        return HttpResponseNotFound(\"Instance with the given id cannot be found.\")\\n\\n    image = getattr(instance, model_data.image_field)\\n    if not bool(image):\\n        return HttpResponseNotFound(\"There is no image for provided instance.\")\\n\\n    # prepare thumbnail\\n    if object_type in ICON_TYPE_TO_MODEL_DATA_MAPPING:\\n        processed_image: ProcessedImage = ProcessedIconImage(\\n            image.name, size_px, format\\n        )\\n    else:\\n        processed_image = ProcessedImage(image.name, size_px, format)\\n    try:\\n        thumbnail_file, _ = processed_image.create_thumbnail()\\n    except FileNotFoundError as error:\\n        logger.info(str(error))\\n        return HttpResponseNotFound(\"Cannot found image file.\")\\n    except ValueError as error:\\n        logger.info(str(error))\\n        return HttpResponseBadRequest(\"Invalid image.\")\\n\\n    thumbnail_file_name = prepare_thumbnail_file_name(image.name, size_px, format)\\n\\n    # save image thumbnail\\n    with allow_writer():\\n        thumbnail = Thumbnail(\\n            size=size_px, format=format, **{model_data.thumbnail_field: instance}\\n        )\\n        thumbnail.image.save(thumbnail_file_name, thumbnail_file)\\n        thumbnail.save()\\n\\n        # set additional `instance` attribute, to easily get instance data\\n        # for ThumbnailCreated subscription type\\n        setattr(thumbnail, \"instance\", instance)\\n        manager = get_plugins_manager(allow_replica=False)\\n        call_event(manager.thumbnail_created, thumbnail)\\n\\n    return HttpResponseRedirect(thumbnail.image.url)', 'content_dafny': 'method handle_thumbnail(request: Request, instance_id: string, size: string, format: string?)\\n  requires instance_id != \"\"\\n  requires size != \"\"\\n  ensures response != null\\n{\\n  var object_type, pk := from_global_id_or_error(instance_id);\\n  if object_type !in TYPE_TO_MODEL_DATA_MAPPING.keys() {\\n    return HttpResponseNotFound(\"Invalid instance type.\");\\n  }\\n\\n  var format_lower := if format != null then format.lower() else null;\\n  if object_type in ICON_TYPE_TO_MODEL_DATA_MAPPING {\\n    if format_lower !in ALLOWED_ICON_THUMBNAIL_FORMATS {\\n      return HttpResponseNotFound(\"Unsupported icon image format.\");\\n    }\\n  } else if format_lower !in ALLOWED_THUMBNAIL_FORMATS {\\n    return HttpResponseNotFound(\"Unsupported image format.\");\\n  }\\n\\n  var size_px := get_thumbnail_size(int(size));\\n  var model_data := TYPE_TO_MODEL_DATA_MAPPING[object_type];\\n  var instance_id_lookup := if object_type in UUID_IDENTIFIABLE_TYPES then model_data.thumbnail_field + \"__uuid\" else model_data.thumbnail_field + \"_id\";\\n\\n  var thumbnail := Thumbnail.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME).filter(format=format_lower, size=size_px, instance_id_lookup=pk).first();\\n  if thumbnail != null {\\n    return HttpResponseRedirect(thumbnail.image.url);\\n  }\\n\\n  var instance := if object_type in UUID_IDENTIFIABLE_TYPES then model_data.model.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME).get(uuid=pk) else model_data.model.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME).get(id=pk);\\n  var image := getattr(instance, model_data.image_field);\\n  if !bool(image) {\\n    return HttpResponseNotFound(\"There is no image for provided instance.\");\\n  }\\n\\n  var processed_image := if object_type in ICON_TYPE_TO_MODEL_DATA_MAPPING then ProcessedIconImage(image.name, size_px, format_lower) else ProcessedImage(image.name, size_px, format_lower);\\n  var thumbnail_file, _ := processed_image.create_thumbnail();\\n\\n  var thumbnail_file_name := prepare_thumbnail_file_name(image.name, size_px, format_lower);\\n\\n  allow_writer();\\n  var thumbnail := Thumbnail(size=size_px, format=format_lower, instance);\\n  thumbnail.image.save(thumbnail_file_name, thumbnail_file);\\n  thumbnail.save();\\n\\n  setattr(thumbnail, \"instance\", instance);\\n  var manager := get_plugins_manager(allow_replica=false);\\n  call_event(manager.thumbnail_created, thumbnail);\\n\\n  return HttpResponseRedirect(thumbnail.image.url);\\n}', 'file_path': '/Users/ryanmarr/Documents/saleor/saleor/thumbnail/views.py'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 2/4045 [00:33<15:51:00, 14.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: [{'name': 'jwks', 'http_method': 'GET', 'description': 'Returns JSON Web Key Set (JWKS) for JWT validation.', 'content_django': 'def jwks(request):\\n    return JsonResponse(get_jwt_manager().get_jwks())', 'content_dafny': 'method jwks(request: Request) returns (response: JsonResponse)\\n  requires request != null\\n  ensures response != null\\n  ensures response.content == get_jwt_manager().get_jwks()', 'file_path': '/Users/ryanmarr/Documents/saleor/saleor/core/views.py'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 3/4045 [00:39<11:56:10, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: [{'name': 'handle_plugin_webhook', 'http_method': 'UNKNOWN', 'description': 'Handles a webhook for a specific plugin without a channel.', 'content_django': '@allow_writer()\\ndef handle_plugin_webhook(request: SaleorContext, plugin_id: str) -> HttpResponse:\\n    manager = get_plugins_manager(allow_replica=False)\\n    return manager.webhook_endpoint_without_channel(request, plugin_id)', 'content_dafny': 'method handle_plugin_webhook(request: SaleorContext, plugin_id: string) returns (response: HttpResponse)\\n  requires request != null && plugin_id != \"\"\\n  ensures response != null\\n{\\n  var manager := get_plugins_manager(false);\\n  response := manager.webhook_endpoint_without_channel(request, plugin_id);\\n}', 'file_path': '/Users/ryanmarr/Documents/saleor/saleor/plugins/views.py'}, {'name': 'handle_global_plugin_webhook', 'http_method': 'UNKNOWN', 'description': 'Handles a global webhook for a specific plugin.', 'content_django': '@allow_writer()\\ndef handle_global_plugin_webhook(\\n    request: SaleorContext, plugin_id: str\\n) -> HttpResponse:\\n    manager = get_plugins_manager(allow_replica=False)\\n    return manager.webhook(request, plugin_id, channel_slug=None)', 'content_dafny': 'method handle_global_plugin_webhook(request: SaleorContext, plugin_id: string) returns (response: HttpResponse)\\n  requires request != null && plugin_id != \"\"\\n  ensures response != null\\n{\\n  var manager := get_plugins_manager(false);\\n  response := manager.webhook(request, plugin_id, null);\\n}', 'file_path': '/Users/ryanmarr/Documents/saleor/saleor/plugins/views.py'}, {'name': 'handle_plugin_per_channel_webhook', 'http_method': 'UNKNOWN', 'description': 'Handles a webhook for a specific plugin and channel.', 'content_django': '@allow_writer()\\ndef handle_plugin_per_channel_webhook(\\n    request: SaleorContext, plugin_id: str, channel_slug: str\\n) -> HttpResponse:\\n    manager = get_plugins_manager(allow_replica=False)\\n    return manager.webhook(request, plugin_id, channel_slug=channel_slug)', 'content_dafny': 'method handle_plugin_per_channel_webhook(request: SaleorContext, plugin_id: string, channel_slug: string) returns (response: HttpResponse)\\n  requires request != null && plugin_id != \"\" && channel_slug != \"\"\\n  ensures response != null\\n{\\n  var manager := get_plugins_manager(false);\\n  response := manager.webhook(request, plugin_id, channel_slug);\\n}', 'file_path': '/Users/ryanmarr/Documents/saleor/saleor/plugins/views.py'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 4/4045 [00:46<10:28:23,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: [{'name': 'digital_product', 'http_method': 'GET', 'description': 'Return the direct download link to content if given token is still valid.', 'content_django': 'def digital_product(request, token: str) -> FileResponse | HttpResponseNotFound:\\n    \"\"\"Return the direct download link to content if given token is still valid.\"\"\"\\n\\n    qs = DigitalContentUrl.objects.using(\\n        settings.DATABASE_CONNECTION_REPLICA_NAME\\n    ).prefetch_related(\"line__order__user\")\\n    content_url = get_object_or_404(qs, token=token)  # type: DigitalContentUrl\\n    if not digital_content_url_is_valid(content_url):\\n        return HttpResponseNotFound(\"Url is not valid anymore\")\\n\\n    digital_content = content_url.content\\n    digital_content.content_file.open()\\n    opened_file = digital_content.content_file.file\\n    filename = os.path.basename(digital_content.content_file.name)\\n    file_expr = f\\'filename=\"{filename}\"\\'\\n\\n    content_type = mimetypes.guess_type(str(filename))[0]\\n    response = FileResponse(opened_file)\\n    response[\"Content-Length\"] = digital_content.content_file.size\\n\\n    response[\"Content-Type\"] = str(content_type)\\n    response[\"Content-Disposition\"] = f\"attachment; {file_expr}\"\\n\\n    increment_download_count(content_url)\\n    return response', 'content_dafny': 'method digital_product(token: string) returns (response: FileResponse | HttpResponseNotFound)\\n  requires exists content_url: DigitalContentUrl :: content_url.token == token && digital_content_url_is_valid(content_url)\\n  ensures response != null\\n{\\n  var content_url := DigitalContentUrl.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME).prefetch_related(\"line__order__user\").get(token);\\n  if (!digital_content_url_is_valid(content_url)) {\\n    return HttpResponseNotFound(\"Url is not valid anymore\");\\n  }\\n\\n  var digital_content := content_url.content;\\n  digital_content.content_file.open();\\n  var opened_file := digital_content.content_file.file;\\n  var filename := os.path.basename(digital_content.content_file.name);\\n  var file_expr := \"filename=\\\\\"\" + filename + \"\\\\\"\";\\n\\n  var content_type := mimetypes.guess_type(filename)[0];\\n  response := FileResponse(opened_file);\\n  response[\"Content-Length\"] := digital_content.content_file.size;\\n\\n  response[\"Content-Type\"] := content_type;\\n  response[\"Content-Disposition\"] := \"attachment; \" + file_expr;\\n\\n  increment_download_count(content_url);\\n  return response;\\n}', 'file_path': '/Users/ryanmarr/Documents/saleor/saleor/product/views.py'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 5/4045 [01:01<12:36:14, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: [{'name': 'dispatch', 'http_method': 'GET|POST', 'description': 'Handles HTTP GET and POST requests for the GraphQL API.', 'content_django': 'def dispatch(self, request, *args, **kwargs):\\n    # Handle options method the GraphQlView restricts it.\\n    if request.method == \"GET\":\\n        if settings.PLAYGROUND_ENABLED:\\n            return self.render_playground(request)\\n        return HttpResponseNotAllowed([\"OPTIONS\", \"POST\"])\\n    if request.method == \"POST\":\\n        return self.handle_query(request)\\n    if settings.PLAYGROUND_ENABLED:\\n        return HttpResponseNotAllowed([\"GET\", \"OPTIONS\", \"POST\"])\\n    return HttpResponseNotAllowed([\"OPTIONS\", \"POST\"])', 'content_dafny': 'method dispatch(request: HttpRequest) returns (response: HttpResponse)\\n    requires request.method in [\"GET\", \"POST\"]\\n    ensures response != null\\n{\\n    if request.method == \"GET\" {\\n        if settings.PLAYGROUND_ENABLED {\\n            response := render_playground(request);\\n        } else {\\n            response := HttpResponseNotAllowed([\"OPTIONS\", \"POST\"]);\\n        }\\n    } else if request.method == \"POST\" {\\n        response := handle_query(request);\\n    } else {\\n        if settings.PLAYGROUND_ENABLED {\\n            response := HttpResponseNotAllowed([\"GET\", \"OPTIONS\", \"POST\"]);\\n        } else {\\n            response := HttpResponseNotAllowed([\"OPTIONS\", \"POST\"]);\\n        }\\n    }\\n}', 'file_path': '/Users/ryanmarr/Documents/saleor/saleor/graphql/views.py'}, {'name': 'handle_query', 'http_method': 'POST', 'description': 'Handles POST requests to process GraphQL queries.', 'content_django': 'def handle_query(self, request: HttpRequest) -> JsonResponse:\\n    with (\\n        tracer.extract_context(request.headers) as context,\\n        tracer.start_as_current_span(\\n            request.path, scope=Scope.SERVICE, kind=SpanKind.SERVER, context=context\\n        ) as span,\\n        record_request_duration() as request_duration_attrs,\\n    ):\\n        span.set_attribute(saleor_attributes.COMPONENT, \"http\")\\n        span.set_attribute(saleor_attributes.OPERATION_NAME, \"http\")\\n        span.set_attribute(http_attributes.HTTP_REQUEST_METHOD, request.method)  # type: ignore[arg-type]\\n        span.set_attribute(\\n            url_attributes.URL_FULL,\\n            request.build_absolute_uri(request.get_full_path()),\\n        )\\n        accepted_encoding = request.headers.get(\"accept-encoding\", \"\")\\n        span.set_attribute(\\n            f\"{http_attributes.HTTP_REQUEST_HEADER_TEMPLATE}.accept-encoding\",\\n            [\"gzip\"] if \"gzip\" in accepted_encoding else [\"none\"],\\n        )\\n        span.set_attribute(\\n            user_agent_attributes.USER_AGENT_ORIGINAL,\\n            request.headers.get(\"user-agent\", \"\"),\\n        )\\n        span.set_attribute(saleor_attributes.SPAN_TYPE, \"web\")\\n\\n        response = self._handle_query(request)\\n        tracer.inject_context(response.headers)\\n        span.set_attribute(\\n            http_attributes.HTTP_RESPONSE_STATUS_CODE, response.status_code\\n        )\\n\\n        # RFC2616: Content-Length is defined in bytes,\\n        # we can calculate the RAW UTF-8 size using the length of\\n        # response.content of type \\'bytes\\'\\n        span.set_attribute(\\n            incubating_http_attributes.HTTP_RESPONSE_BODY_SIZE,\\n            len(response.content),\\n        )\\n\\n        error_type = (\\n            str(response.status_code) if response.status_code >= 500 else None\\n        )\\n        record_request_count(error_type=error_type)\\n        if error_type:\\n            request_duration_attrs[error_attributes.ERROR_TYPE] = error_type\\n\\n        with observability.report_api_call(request) as api_call:\\n            api_call.response = response\\n            api_call.report()\\n        return response', 'content_dafny': 'method handle_query(request: HttpRequest) returns (response: JsonResponse)\\n    requires request.method == \"POST\"\\n    ensures response != null\\n{\\n    var context := tracer.extract_context(request.headers);\\n    var span := tracer.start_as_current_span(request.path, scope := Scope.SERVICE, kind := SpanKind.SERVER, context := context);\\n    var request_duration_attrs := record_request_duration();\\n\\n    span.set_attribute(saleor_attributes.COMPONENT, \"http\");\\n    span.set_attribute(saleor_attributes.OPERATION_NAME, \"http\");\\n    span.set_attribute(http_attributes.HTTP_REQUEST_METHOD, request.method);\\n    span.set_attribute(url_attributes.URL_FULL, request.build_absolute_uri(request.get_full_path()));\\n    var accepted_encoding := request.headers.get(\"accept-encoding\", \"\");\\n    span.set_attribute(http_attributes.HTTP_REQUEST_HEADER_TEMPLATE + \".accept-encoding\", if \"gzip\" in accepted_encoding then [\"gzip\"] else [\"none\"]);\\n    span.set_attribute(user_agent_attributes.USER_AGENT_ORIGINAL, request.headers.get(\"user-agent\", \"\"));\\n    span.set_attribute(saleor_attributes.SPAN_TYPE, \"web\");\\n\\n    response := _handle_query(request);\\n    tracer.inject_context(response.headers);\\n    span.set_attribute(http_attributes.HTTP_RESPONSE_STATUS_CODE, response.status_code);\\n    span.set_attribute(incubating_http_attributes.HTTP_RESPONSE_BODY_SIZE, len(response.content));\\n\\n    var error_type := if response.status_code >= 500 then response.status_code.ToString() else null;\\n    record_request_count(error_type := error_type);\\n    if error_type != null {\\n        request_duration_attrs[error_attributes.ERROR_TYPE] := error_type;\\n    }\\n\\n    var api_call := observability.report_api_call(request);\\n    api_call.response := response;\\n    api_call.report();\\n    return response;\\n}', 'file_path': '/Users/ryanmarr/Documents/saleor/saleor/graphql/views.py'}]\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 9/4045 [01:02<4:16:34,  3.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 11/4045 [01:03<3:08:23,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 12/4045 [01:04<2:42:12,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 13/4045 [01:05<2:15:18,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 15/4045 [01:06<1:40:15,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 16/4045 [01:07<1:30:09,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 17/4045 [01:08<1:26:15,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 18/4045 [01:08<1:18:59,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 22/4045 [01:10<50:53,  1.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 25/4045 [01:15<1:07:16,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 26/4045 [01:17<1:26:47,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 28/4045 [01:18<1:08:22,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 38/4045 [01:19<24:58,  2.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 39/4045 [01:20<26:35,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 40/4045 [01:22<37:31,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 42/4045 [01:22<34:58,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 44/4045 [01:27<1:05:47,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 45/4045 [01:37<2:38:57,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 46/4045 [01:42<3:08:04,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 48/4045 [01:42<2:11:47,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 49/4045 [01:43<1:53:54,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 50/4045 [01:59<5:25:50,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|▏         | 51/4045 [02:00<4:25:01,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|▏         | 53/4045 [02:01<2:51:25,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|▏         | 54/4045 [02:04<2:49:34,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|▏         | 55/4045 [02:08<3:13:01,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|▏         | 56/4045 [02:10<3:01:42,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|▏         | 57/4045 [02:15<3:48:01,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|▏         | 58/4045 [02:22<4:54:56,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 62/4045 [02:32<3:30:34,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 65/4045 [02:34<2:22:29,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 66/4045 [02:41<3:13:12,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 67/4045 [02:42<2:54:58,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 70/4045 [02:45<2:06:39,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 73/4045 [02:49<1:48:04,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 75/4045 [02:49<1:23:43,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 76/4045 [02:53<1:53:40,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 77/4045 [02:54<1:41:29,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 78/4045 [03:03<3:31:24,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 79/4045 [03:04<2:54:14,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 80/4045 [03:08<3:15:18,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 83/4045 [04:05<12:15:17, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 84/4045 [04:05<9:56:04,  9.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 85/4045 [04:06<7:58:59,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 86/4045 [04:07<6:22:14,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 87/4045 [04:26<9:54:24,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 89/4045 [04:30<6:42:49,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 90/4045 [04:30<5:18:16,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 91/4045 [04:31<4:12:14,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 92/4045 [04:35<4:21:03,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n",
      "apis: []\n",
      "apis: []\n",
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 96/4045 [04:36<1:53:23,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 97/4045 [04:56<5:21:27,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 97/4045 [04:57<3:21:50,  3.07s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/openai/_base_client.py:1027\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1027\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/httpx/_models.py:829\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m all_apis \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m tqdm(django_files, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyzing files\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     apis \u001b[38;5;241m=\u001b[39m \u001b[43mextract_rest_apis_from_file_with_openai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapis: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     all_apis\u001b[38;5;241m.\u001b[39mextend(apis)\n",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m, in \u001b[0;36mextract_rest_apis_from_file_with_openai\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mAnalyze this Python file and identify all Django REST API functions or classes. Only return the functions that are REST API endpoints. Only return entire implemenation of the function including function signature and content. \u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124mDo not include any text before or after the JSON.\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_TOKENS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOP_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTREAM\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     response \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Improved JSON extraction\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py:1150\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1148\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1149\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/openai/_base_client.py:1033\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1032\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1033\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/openai/_base_client.py:1073\u001b[0m, in \u001b[0;36mSyncAPIClient._sleep_for_retry\u001b[0;34m(self, retries_taken, max_retries, options, response)\u001b[0m\n\u001b[1;32m   1070\u001b[0m timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_retry_timeout(remaining_retries, options, response\u001b[38;5;241m.\u001b[39mheaders \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1071\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[0;32m-> 1073\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Analyze Django project and generate Dafny specifications\"\"\"\n",
    "\n",
    "# Find all Python files\n",
    "django_files = find_django_files(DJANGO_PROJECT_PATH)\n",
    "print(f\"Found {len(django_files)} Python files\")\n",
    "\n",
    "# Extract REST APIs using OpenAI\n",
    "all_apis = []\n",
    "for file_path in tqdm(django_files, desc=\"Analyzing files\"):\n",
    "    apis = extract_rest_apis_from_file_with_openai(file_path)\n",
    "    print(f'apis: {apis}')\n",
    "    all_apis.extend(apis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "249bbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_full_api_info(apis: List[Dict[str, Any]]):\n",
    "    \"\"\"Display complete API information with full Django code and Dafny specs\"\"\"\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(\"COMPLETE DJANGO REST API ANALYSIS\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Total APIs found: {len(apis)}\")\n",
    "    print()\n",
    "    \n",
    "    # Group by file path\n",
    "    files = {}\n",
    "    for api in apis:\n",
    "        file_path = api.get('file_path', 'Unknown')\n",
    "        if file_path not in files:\n",
    "            files[file_path] = []\n",
    "        files[file_path].append(api)\n",
    "    \n",
    "    # Display by file\n",
    "    for file_path, file_apis in files.items():\n",
    "        print(f\"📁 FILE: {file_path}\")\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"APIs found: {len(file_apis)}\")\n",
    "        print()\n",
    "        \n",
    "        for i, api in enumerate(file_apis, 1):\n",
    "            print(f\"🔗 API #{i}: {api.get('name', 'Unknown')}\")\n",
    "            print(f\"   Method: {api.get('http_method', 'UNKNOWN')}\")\n",
    "            print(f\"   Description: {api.get('description', 'No description')}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"📝 DJANGO CODE:\")\n",
    "            print(\"-\" * 50)\n",
    "            django_code = api.get('content_django', 'No Django code available')\n",
    "            print(django_code)\n",
    "            print()\n",
    "            \n",
    "            print(\"🔬 DAFNY SPECIFICATION:\")\n",
    "            print(\"-\" * 50)\n",
    "            dafny_spec = api.get('content_dafny', 'No Dafny specification available')\n",
    "            print(dafny_spec)\n",
    "            print()\n",
    "            \n",
    "            print(\"─\" * 100)\n",
    "            print()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"=\" * 100)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # HTTP method distribution\n",
    "    methods = {}\n",
    "    for api in apis:\n",
    "        method = api.get('http_method', 'UNKNOWN')\n",
    "        methods[method] = methods.get(method, 0) + 1\n",
    "    \n",
    "    print(\"HTTP Methods:\")\n",
    "    for method, count in sorted(methods.items()):\n",
    "        print(f\"  {method}: {count}\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Files analyzed: {len(files)}\")\n",
    "    print(f\"Total APIs: {len(apis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f23afccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "COMPLETE DJANGO REST API ANALYSIS\n",
      "====================================================================================================\n",
      "Total APIs found: 8\n",
      "\n",
      "📁 FILE: /Users/ryanmarr/Documents/saleor/saleor/thumbnail/views.py\n",
      "====================================================================================================\n",
      "APIs found: 1\n",
      "\n",
      "🔗 API #1: handle_thumbnail\n",
      "   Method: UNKNOWN\n",
      "   Description: Create and return thumbnail for given instance in provided size and format.\n",
      "\n",
      "📝 DJANGO CODE:\n",
      "--------------------------------------------------\n",
      "def handle_thumbnail(request, instance_id: str, size: str, format: str | None = None):\n",
      "    \"\"\"Create and return thumbnail for given instance in provided size and format.\n",
      "\n",
      "    If the provided size is not in the available resolution list, the thumbnail with\n",
      "    the closest available size is created and returned, if it does not exist.\n",
      "    \"\"\"\n",
      "    # try to find corresponding instance based on given instance_id\n",
      "    try:\n",
      "        object_type, pk = from_global_id_or_error(instance_id, raise_error=True)\n",
      "    except GraphQLError:\n",
      "        return HttpResponseNotFound(\"Cannot found instance with the given id.\")\n",
      "\n",
      "    if object_type not in TYPE_TO_MODEL_DATA_MAPPING.keys():\n",
      "        return HttpResponseNotFound(\"Invalid instance type.\")\n",
      "\n",
      "    # check formats\n",
      "    format = format.lower() if format else None\n",
      "    if object_type in ICON_TYPE_TO_MODEL_DATA_MAPPING:\n",
      "        if format and format not in ALLOWED_ICON_THUMBNAIL_FORMATS:\n",
      "            return HttpResponseNotFound(\"Unsupported icon image format.\")\n",
      "    elif format and format not in ALLOWED_THUMBNAIL_FORMATS:\n",
      "        return HttpResponseNotFound(\"Unsupported image format.\")\n",
      "\n",
      "    try:\n",
      "        size_px = get_thumbnail_size(int(size))\n",
      "    except ValueError:\n",
      "        return HttpResponseNotFound(\"Invalid size.\")\n",
      "\n",
      "    # return the thumbnail if it's already exist\n",
      "    model_data = TYPE_TO_MODEL_DATA_MAPPING[object_type]\n",
      "    if object_type in UUID_IDENTIFIABLE_TYPES:\n",
      "        instance_id_lookup = model_data.thumbnail_field + \"__uuid\"\n",
      "    else:\n",
      "        instance_id_lookup = model_data.thumbnail_field + \"_id\"\n",
      "\n",
      "    if (\n",
      "        thumbnail := Thumbnail.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME)\n",
      "        .filter(format=format, size=size_px, **{instance_id_lookup: pk})\n",
      "        .first()\n",
      "    ):\n",
      "        return HttpResponseRedirect(thumbnail.image.url)\n",
      "\n",
      "    try:\n",
      "        if object_type in UUID_IDENTIFIABLE_TYPES:\n",
      "            instance = model_data.model.objects.using(\n",
      "                settings.DATABASE_CONNECTION_REPLICA_NAME\n",
      "            ).get(uuid=pk)  # type: ignore[misc]\n",
      "        else:\n",
      "            instance = model_data.model.objects.using(\n",
      "                settings.DATABASE_CONNECTION_REPLICA_NAME\n",
      "            ).get(id=pk)\n",
      "    except ObjectDoesNotExist:\n",
      "        return HttpResponseNotFound(\"Instance with the given id cannot be found.\")\n",
      "\n",
      "    image = getattr(instance, model_data.image_field)\n",
      "    if not bool(image):\n",
      "        return HttpResponseNotFound(\"There is no image for provided instance.\")\n",
      "\n",
      "    # prepare thumbnail\n",
      "    if object_type in ICON_TYPE_TO_MODEL_DATA_MAPPING:\n",
      "        processed_image: ProcessedImage = ProcessedIconImage(\n",
      "            image.name, size_px, format\n",
      "        )\n",
      "    else:\n",
      "        processed_image = ProcessedImage(image.name, size_px, format)\n",
      "    try:\n",
      "        thumbnail_file, _ = processed_image.create_thumbnail()\n",
      "    except FileNotFoundError as error:\n",
      "        logger.info(str(error))\n",
      "        return HttpResponseNotFound(\"Cannot found image file.\")\n",
      "    except ValueError as error:\n",
      "        logger.info(str(error))\n",
      "        return HttpResponseBadRequest(\"Invalid image.\")\n",
      "\n",
      "    thumbnail_file_name = prepare_thumbnail_file_name(image.name, size_px, format)\n",
      "\n",
      "    # save image thumbnail\n",
      "    with allow_writer():\n",
      "        thumbnail = Thumbnail(\n",
      "            size=size_px, format=format, **{model_data.thumbnail_field: instance}\n",
      "        )\n",
      "        thumbnail.image.save(thumbnail_file_name, thumbnail_file)\n",
      "        thumbnail.save()\n",
      "\n",
      "        # set additional `instance` attribute, to easily get instance data\n",
      "        # for ThumbnailCreated subscription type\n",
      "        setattr(thumbnail, \"instance\", instance)\n",
      "        manager = get_plugins_manager(allow_replica=False)\n",
      "        call_event(manager.thumbnail_created, thumbnail)\n",
      "\n",
      "    return HttpResponseRedirect(thumbnail.image.url)\n",
      "\n",
      "🔬 DAFNY SPECIFICATION:\n",
      "--------------------------------------------------\n",
      "method handle_thumbnail(request: Request, instance_id: string, size: string, format: string?)\n",
      "  requires instance_id != \"\"\n",
      "  requires size != \"\"\n",
      "  ensures response != null\n",
      "{\n",
      "  var object_type, pk := from_global_id_or_error(instance_id);\n",
      "  if object_type !in TYPE_TO_MODEL_DATA_MAPPING.keys() {\n",
      "    return HttpResponseNotFound(\"Invalid instance type.\");\n",
      "  }\n",
      "\n",
      "  var format_lower := if format != null then format.lower() else null;\n",
      "  if object_type in ICON_TYPE_TO_MODEL_DATA_MAPPING {\n",
      "    if format_lower !in ALLOWED_ICON_THUMBNAIL_FORMATS {\n",
      "      return HttpResponseNotFound(\"Unsupported icon image format.\");\n",
      "    }\n",
      "  } else if format_lower !in ALLOWED_THUMBNAIL_FORMATS {\n",
      "    return HttpResponseNotFound(\"Unsupported image format.\");\n",
      "  }\n",
      "\n",
      "  var size_px := get_thumbnail_size(int(size));\n",
      "  var model_data := TYPE_TO_MODEL_DATA_MAPPING[object_type];\n",
      "  var instance_id_lookup := if object_type in UUID_IDENTIFIABLE_TYPES then model_data.thumbnail_field + \"__uuid\" else model_data.thumbnail_field + \"_id\";\n",
      "\n",
      "  var thumbnail := Thumbnail.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME).filter(format=format_lower, size=size_px, instance_id_lookup=pk).first();\n",
      "  if thumbnail != null {\n",
      "    return HttpResponseRedirect(thumbnail.image.url);\n",
      "  }\n",
      "\n",
      "  var instance := if object_type in UUID_IDENTIFIABLE_TYPES then model_data.model.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME).get(uuid=pk) else model_data.model.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME).get(id=pk);\n",
      "  var image := getattr(instance, model_data.image_field);\n",
      "  if !bool(image) {\n",
      "    return HttpResponseNotFound(\"There is no image for provided instance.\");\n",
      "  }\n",
      "\n",
      "  var processed_image := if object_type in ICON_TYPE_TO_MODEL_DATA_MAPPING then ProcessedIconImage(image.name, size_px, format_lower) else ProcessedImage(image.name, size_px, format_lower);\n",
      "  var thumbnail_file, _ := processed_image.create_thumbnail();\n",
      "\n",
      "  var thumbnail_file_name := prepare_thumbnail_file_name(image.name, size_px, format_lower);\n",
      "\n",
      "  allow_writer();\n",
      "  var thumbnail := Thumbnail(size=size_px, format=format_lower, instance);\n",
      "  thumbnail.image.save(thumbnail_file_name, thumbnail_file);\n",
      "  thumbnail.save();\n",
      "\n",
      "  setattr(thumbnail, \"instance\", instance);\n",
      "  var manager := get_plugins_manager(allow_replica=false);\n",
      "  call_event(manager.thumbnail_created, thumbnail);\n",
      "\n",
      "  return HttpResponseRedirect(thumbnail.image.url);\n",
      "}\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "📁 FILE: /Users/ryanmarr/Documents/saleor/saleor/core/views.py\n",
      "====================================================================================================\n",
      "APIs found: 1\n",
      "\n",
      "🔗 API #1: jwks\n",
      "   Method: GET\n",
      "   Description: Returns JSON Web Key Set (JWKS) for JWT validation.\n",
      "\n",
      "📝 DJANGO CODE:\n",
      "--------------------------------------------------\n",
      "def jwks(request):\n",
      "    return JsonResponse(get_jwt_manager().get_jwks())\n",
      "\n",
      "🔬 DAFNY SPECIFICATION:\n",
      "--------------------------------------------------\n",
      "method jwks(request: Request) returns (response: JsonResponse)\n",
      "  requires request != null\n",
      "  ensures response != null\n",
      "  ensures response.content == get_jwt_manager().get_jwks()\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "📁 FILE: /Users/ryanmarr/Documents/saleor/saleor/plugins/views.py\n",
      "====================================================================================================\n",
      "APIs found: 3\n",
      "\n",
      "🔗 API #1: handle_plugin_webhook\n",
      "   Method: UNKNOWN\n",
      "   Description: Handles a webhook for a specific plugin without a channel.\n",
      "\n",
      "📝 DJANGO CODE:\n",
      "--------------------------------------------------\n",
      "@allow_writer()\n",
      "def handle_plugin_webhook(request: SaleorContext, plugin_id: str) -> HttpResponse:\n",
      "    manager = get_plugins_manager(allow_replica=False)\n",
      "    return manager.webhook_endpoint_without_channel(request, plugin_id)\n",
      "\n",
      "🔬 DAFNY SPECIFICATION:\n",
      "--------------------------------------------------\n",
      "method handle_plugin_webhook(request: SaleorContext, plugin_id: string) returns (response: HttpResponse)\n",
      "  requires request != null && plugin_id != \"\"\n",
      "  ensures response != null\n",
      "{\n",
      "  var manager := get_plugins_manager(false);\n",
      "  response := manager.webhook_endpoint_without_channel(request, plugin_id);\n",
      "}\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "🔗 API #2: handle_global_plugin_webhook\n",
      "   Method: UNKNOWN\n",
      "   Description: Handles a global webhook for a specific plugin.\n",
      "\n",
      "📝 DJANGO CODE:\n",
      "--------------------------------------------------\n",
      "@allow_writer()\n",
      "def handle_global_plugin_webhook(\n",
      "    request: SaleorContext, plugin_id: str\n",
      ") -> HttpResponse:\n",
      "    manager = get_plugins_manager(allow_replica=False)\n",
      "    return manager.webhook(request, plugin_id, channel_slug=None)\n",
      "\n",
      "🔬 DAFNY SPECIFICATION:\n",
      "--------------------------------------------------\n",
      "method handle_global_plugin_webhook(request: SaleorContext, plugin_id: string) returns (response: HttpResponse)\n",
      "  requires request != null && plugin_id != \"\"\n",
      "  ensures response != null\n",
      "{\n",
      "  var manager := get_plugins_manager(false);\n",
      "  response := manager.webhook(request, plugin_id, null);\n",
      "}\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "🔗 API #3: handle_plugin_per_channel_webhook\n",
      "   Method: UNKNOWN\n",
      "   Description: Handles a webhook for a specific plugin and channel.\n",
      "\n",
      "📝 DJANGO CODE:\n",
      "--------------------------------------------------\n",
      "@allow_writer()\n",
      "def handle_plugin_per_channel_webhook(\n",
      "    request: SaleorContext, plugin_id: str, channel_slug: str\n",
      ") -> HttpResponse:\n",
      "    manager = get_plugins_manager(allow_replica=False)\n",
      "    return manager.webhook(request, plugin_id, channel_slug=channel_slug)\n",
      "\n",
      "🔬 DAFNY SPECIFICATION:\n",
      "--------------------------------------------------\n",
      "method handle_plugin_per_channel_webhook(request: SaleorContext, plugin_id: string, channel_slug: string) returns (response: HttpResponse)\n",
      "  requires request != null && plugin_id != \"\" && channel_slug != \"\"\n",
      "  ensures response != null\n",
      "{\n",
      "  var manager := get_plugins_manager(false);\n",
      "  response := manager.webhook(request, plugin_id, channel_slug);\n",
      "}\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "📁 FILE: /Users/ryanmarr/Documents/saleor/saleor/product/views.py\n",
      "====================================================================================================\n",
      "APIs found: 1\n",
      "\n",
      "🔗 API #1: digital_product\n",
      "   Method: GET\n",
      "   Description: Return the direct download link to content if given token is still valid.\n",
      "\n",
      "📝 DJANGO CODE:\n",
      "--------------------------------------------------\n",
      "def digital_product(request, token: str) -> FileResponse | HttpResponseNotFound:\n",
      "    \"\"\"Return the direct download link to content if given token is still valid.\"\"\"\n",
      "\n",
      "    qs = DigitalContentUrl.objects.using(\n",
      "        settings.DATABASE_CONNECTION_REPLICA_NAME\n",
      "    ).prefetch_related(\"line__order__user\")\n",
      "    content_url = get_object_or_404(qs, token=token)  # type: DigitalContentUrl\n",
      "    if not digital_content_url_is_valid(content_url):\n",
      "        return HttpResponseNotFound(\"Url is not valid anymore\")\n",
      "\n",
      "    digital_content = content_url.content\n",
      "    digital_content.content_file.open()\n",
      "    opened_file = digital_content.content_file.file\n",
      "    filename = os.path.basename(digital_content.content_file.name)\n",
      "    file_expr = f'filename=\"{filename}\"'\n",
      "\n",
      "    content_type = mimetypes.guess_type(str(filename))[0]\n",
      "    response = FileResponse(opened_file)\n",
      "    response[\"Content-Length\"] = digital_content.content_file.size\n",
      "\n",
      "    response[\"Content-Type\"] = str(content_type)\n",
      "    response[\"Content-Disposition\"] = f\"attachment; {file_expr}\"\n",
      "\n",
      "    increment_download_count(content_url)\n",
      "    return response\n",
      "\n",
      "🔬 DAFNY SPECIFICATION:\n",
      "--------------------------------------------------\n",
      "method digital_product(token: string) returns (response: FileResponse | HttpResponseNotFound)\n",
      "  requires exists content_url: DigitalContentUrl :: content_url.token == token && digital_content_url_is_valid(content_url)\n",
      "  ensures response != null\n",
      "{\n",
      "  var content_url := DigitalContentUrl.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME).prefetch_related(\"line__order__user\").get(token);\n",
      "  if (!digital_content_url_is_valid(content_url)) {\n",
      "    return HttpResponseNotFound(\"Url is not valid anymore\");\n",
      "  }\n",
      "\n",
      "  var digital_content := content_url.content;\n",
      "  digital_content.content_file.open();\n",
      "  var opened_file := digital_content.content_file.file;\n",
      "  var filename := os.path.basename(digital_content.content_file.name);\n",
      "  var file_expr := \"filename=\\\"\" + filename + \"\\\"\";\n",
      "\n",
      "  var content_type := mimetypes.guess_type(filename)[0];\n",
      "  response := FileResponse(opened_file);\n",
      "  response[\"Content-Length\"] := digital_content.content_file.size;\n",
      "\n",
      "  response[\"Content-Type\"] := content_type;\n",
      "  response[\"Content-Disposition\"] := \"attachment; \" + file_expr;\n",
      "\n",
      "  increment_download_count(content_url);\n",
      "  return response;\n",
      "}\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "📁 FILE: /Users/ryanmarr/Documents/saleor/saleor/graphql/views.py\n",
      "====================================================================================================\n",
      "APIs found: 2\n",
      "\n",
      "🔗 API #1: dispatch\n",
      "   Method: GET|POST\n",
      "   Description: Handles HTTP GET and POST requests for the GraphQL API.\n",
      "\n",
      "📝 DJANGO CODE:\n",
      "--------------------------------------------------\n",
      "def dispatch(self, request, *args, **kwargs):\n",
      "    # Handle options method the GraphQlView restricts it.\n",
      "    if request.method == \"GET\":\n",
      "        if settings.PLAYGROUND_ENABLED:\n",
      "            return self.render_playground(request)\n",
      "        return HttpResponseNotAllowed([\"OPTIONS\", \"POST\"])\n",
      "    if request.method == \"POST\":\n",
      "        return self.handle_query(request)\n",
      "    if settings.PLAYGROUND_ENABLED:\n",
      "        return HttpResponseNotAllowed([\"GET\", \"OPTIONS\", \"POST\"])\n",
      "    return HttpResponseNotAllowed([\"OPTIONS\", \"POST\"])\n",
      "\n",
      "🔬 DAFNY SPECIFICATION:\n",
      "--------------------------------------------------\n",
      "method dispatch(request: HttpRequest) returns (response: HttpResponse)\n",
      "    requires request.method in [\"GET\", \"POST\"]\n",
      "    ensures response != null\n",
      "{\n",
      "    if request.method == \"GET\" {\n",
      "        if settings.PLAYGROUND_ENABLED {\n",
      "            response := render_playground(request);\n",
      "        } else {\n",
      "            response := HttpResponseNotAllowed([\"OPTIONS\", \"POST\"]);\n",
      "        }\n",
      "    } else if request.method == \"POST\" {\n",
      "        response := handle_query(request);\n",
      "    } else {\n",
      "        if settings.PLAYGROUND_ENABLED {\n",
      "            response := HttpResponseNotAllowed([\"GET\", \"OPTIONS\", \"POST\"]);\n",
      "        } else {\n",
      "            response := HttpResponseNotAllowed([\"OPTIONS\", \"POST\"]);\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "🔗 API #2: handle_query\n",
      "   Method: POST\n",
      "   Description: Handles POST requests to process GraphQL queries.\n",
      "\n",
      "📝 DJANGO CODE:\n",
      "--------------------------------------------------\n",
      "def handle_query(self, request: HttpRequest) -> JsonResponse:\n",
      "    with (\n",
      "        tracer.extract_context(request.headers) as context,\n",
      "        tracer.start_as_current_span(\n",
      "            request.path, scope=Scope.SERVICE, kind=SpanKind.SERVER, context=context\n",
      "        ) as span,\n",
      "        record_request_duration() as request_duration_attrs,\n",
      "    ):\n",
      "        span.set_attribute(saleor_attributes.COMPONENT, \"http\")\n",
      "        span.set_attribute(saleor_attributes.OPERATION_NAME, \"http\")\n",
      "        span.set_attribute(http_attributes.HTTP_REQUEST_METHOD, request.method)  # type: ignore[arg-type]\n",
      "        span.set_attribute(\n",
      "            url_attributes.URL_FULL,\n",
      "            request.build_absolute_uri(request.get_full_path()),\n",
      "        )\n",
      "        accepted_encoding = request.headers.get(\"accept-encoding\", \"\")\n",
      "        span.set_attribute(\n",
      "            f\"{http_attributes.HTTP_REQUEST_HEADER_TEMPLATE}.accept-encoding\",\n",
      "            [\"gzip\"] if \"gzip\" in accepted_encoding else [\"none\"],\n",
      "        )\n",
      "        span.set_attribute(\n",
      "            user_agent_attributes.USER_AGENT_ORIGINAL,\n",
      "            request.headers.get(\"user-agent\", \"\"),\n",
      "        )\n",
      "        span.set_attribute(saleor_attributes.SPAN_TYPE, \"web\")\n",
      "\n",
      "        response = self._handle_query(request)\n",
      "        tracer.inject_context(response.headers)\n",
      "        span.set_attribute(\n",
      "            http_attributes.HTTP_RESPONSE_STATUS_CODE, response.status_code\n",
      "        )\n",
      "\n",
      "        # RFC2616: Content-Length is defined in bytes,\n",
      "        # we can calculate the RAW UTF-8 size using the length of\n",
      "        # response.content of type 'bytes'\n",
      "        span.set_attribute(\n",
      "            incubating_http_attributes.HTTP_RESPONSE_BODY_SIZE,\n",
      "            len(response.content),\n",
      "        )\n",
      "\n",
      "        error_type = (\n",
      "            str(response.status_code) if response.status_code >= 500 else None\n",
      "        )\n",
      "        record_request_count(error_type=error_type)\n",
      "        if error_type:\n",
      "            request_duration_attrs[error_attributes.ERROR_TYPE] = error_type\n",
      "\n",
      "        with observability.report_api_call(request) as api_call:\n",
      "            api_call.response = response\n",
      "            api_call.report()\n",
      "        return response\n",
      "\n",
      "🔬 DAFNY SPECIFICATION:\n",
      "--------------------------------------------------\n",
      "method handle_query(request: HttpRequest) returns (response: JsonResponse)\n",
      "    requires request.method == \"POST\"\n",
      "    ensures response != null\n",
      "{\n",
      "    var context := tracer.extract_context(request.headers);\n",
      "    var span := tracer.start_as_current_span(request.path, scope := Scope.SERVICE, kind := SpanKind.SERVER, context := context);\n",
      "    var request_duration_attrs := record_request_duration();\n",
      "\n",
      "    span.set_attribute(saleor_attributes.COMPONENT, \"http\");\n",
      "    span.set_attribute(saleor_attributes.OPERATION_NAME, \"http\");\n",
      "    span.set_attribute(http_attributes.HTTP_REQUEST_METHOD, request.method);\n",
      "    span.set_attribute(url_attributes.URL_FULL, request.build_absolute_uri(request.get_full_path()));\n",
      "    var accepted_encoding := request.headers.get(\"accept-encoding\", \"\");\n",
      "    span.set_attribute(http_attributes.HTTP_REQUEST_HEADER_TEMPLATE + \".accept-encoding\", if \"gzip\" in accepted_encoding then [\"gzip\"] else [\"none\"]);\n",
      "    span.set_attribute(user_agent_attributes.USER_AGENT_ORIGINAL, request.headers.get(\"user-agent\", \"\"));\n",
      "    span.set_attribute(saleor_attributes.SPAN_TYPE, \"web\");\n",
      "\n",
      "    response := _handle_query(request);\n",
      "    tracer.inject_context(response.headers);\n",
      "    span.set_attribute(http_attributes.HTTP_RESPONSE_STATUS_CODE, response.status_code);\n",
      "    span.set_attribute(incubating_http_attributes.HTTP_RESPONSE_BODY_SIZE, len(response.content));\n",
      "\n",
      "    var error_type := if response.status_code >= 500 then response.status_code.ToString() else null;\n",
      "    record_request_count(error_type := error_type);\n",
      "    if error_type != null {\n",
      "        request_duration_attrs[error_attributes.ERROR_TYPE] := error_type;\n",
      "    }\n",
      "\n",
      "    var api_call := observability.report_api_call(request);\n",
      "    api_call.response := response;\n",
      "    api_call.report();\n",
      "    return response;\n",
      "}\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY STATISTICS\n",
      "====================================================================================================\n",
      "HTTP Methods:\n",
      "  GET: 2\n",
      "  GET|POST: 1\n",
      "  POST: 1\n",
      "  UNKNOWN: 4\n",
      "\n",
      "Files analyzed: 5\n",
      "Total APIs: 8\n"
     ]
    }
   ],
   "source": [
    "display_full_api_info(all_apis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".duct_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
