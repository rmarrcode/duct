{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2978067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "DJANGO_PROJECT_PATH = \"/Users/ryanmarr/Documents/saleor\"\n",
    "MODEL_NAME = \"deepseek-r1-distill-llama-70b\"\n",
    "MAX_TOKENS = 2048\n",
    "TEMPERATURE = 0.1\n",
    "TOP_P = 1\n",
    "STREAM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14418da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq client setup\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa98c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_django_files(directory: str) -> List[str]:\n",
    "    \"\"\"Perform DFS to find all Python files in Django project\"\"\"\n",
    "    django_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Skip common directories that don't contain Django code\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', 'env', '.git']]\n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                django_files.append(file_path)\n",
    "    \n",
    "    return django_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rest_apis_from_file_with_openai(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Use OpenAI to analyze file content and find REST APIs\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()  \n",
    "        \n",
    "        # Skip files that don't contain common Django/API keywords\n",
    "        if not any(keyword in content.lower() for keyword in ['api', 'view', 'rest', 'http', 'request', 'response', 'serializer']):\n",
    "            return []\n",
    "\n",
    "        # Limit content to avoid token limits\n",
    "        content = content[:8000]  # OpenAI can handle more content\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Analyze this Python file and identify all Django REST API functions or classes. Only return the functions that are REST API endpoints. Only return entire implementation of the function including function signature and content. \n",
    "        \n",
    "        File: {file_path}\n",
    "        \n",
    "        Look for:\n",
    "        1. Functions that handle HTTP methods (GET, POST, PUT, DELETE, PATCH)\n",
    "        2. Functions that process requests and return responses\n",
    "        3. Any other REST API endpoints\n",
    "        \n",
    "        File content:\n",
    "        {content}\n",
    "        \n",
    "        IMPORTANT: Return ONLY valid JSON with this exact structure:\n",
    "        {{\n",
    "            \"apis\": [\n",
    "                {{\n",
    "                    \"name\": \"function_or_class_name\",\n",
    "                    \"http_method\": \"GET|POST|PUT|DELETE|PATCH|UNKNOWN\",\n",
    "                    \"description\": \"Brief description of what this API does\",\n",
    "                    \"content_django\": \"actual function and entire implementation function include function signature and content\",\n",
    "                    \"content_dafny\": \"Based on the django function, create a Dafny function specification with preconditions and postconditions assume db schema exists as a dafny type\"\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \n",
    "        If no REST APIs are found, return: {{\"apis\": []}}\n",
    "        Do not include any text before or after the JSON.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                temperature=TEMPERATURE,\n",
    "                max_tokens=MAX_TOKENS,\n",
    "                top_p=TOP_P,\n",
    "                stream=STREAM\n",
    "            )\n",
    "            \n",
    "            response = completion.choices[0].message.content.strip()\n",
    "            \n",
    "            # Try to extract JSON from the response\n",
    "            json_match = re.search(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(0)\n",
    "                try:\n",
    "                    result = json.loads(json_str)\n",
    "                    for api in result.get('apis', []):\n",
    "                        api['file_path'] = file_path\n",
    "                    return result.get('apis', [])\n",
    "                    \n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to parse JSON from response for {file_path}\")\n",
    "                    print(f\"Response: {response}\")\n",
    "                    return []\n",
    "            else:\n",
    "                print(f\"No JSON found in response for {file_path}\")\n",
    "                print(f\"Response: {response}\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error calling OpenAI API for {file_path}: {e}\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3434058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4045 Python files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 4/4045 [00:01<28:57,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/settings.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 10782, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 17/4045 [01:05<4:59:36,  4.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/payloads.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 13265, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/event_types.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 9046, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 44/4045 [03:46<7:59:40,  7.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/transport/asynchronous/transport.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 8290, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 78/4045 [10:43<9:47:48,  8.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/test_webhook_payloads.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 27405, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 81/4045 [11:53<16:36:37, 15.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/test_tasks.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 9361, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 91/4045 [13:23<8:45:36,  7.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/response_schemas/test_transaction.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 9200, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 96/4045 [14:04<8:31:43,  7.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/response_schemas/test_payment.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 6843, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 100/4045 [15:10<13:58:17, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_taxes.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 14884, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   3%|▎         | 104/4045 [15:21<7:29:29,  6.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_subscription.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 28295, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   3%|▎         | 112/4045 [17:11<13:24:13, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/subscription_webhooks/subscription_queries.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 12199, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   3%|▎         | 116/4045 [17:39<9:57:56,  9.13s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/groq/_base_client.py:1014\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1014\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/httpx/_models.py:829\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m all_apis \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m tqdm(django_files, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyzing files\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     apis \u001b[38;5;241m=\u001b[39m \u001b[43mextract_rest_apis_from_file_with_groq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     all_apis\u001b[38;5;241m.\u001b[39mextend(apis)\n",
      "Cell \u001b[0;32mIn[5], line 45\u001b[0m, in \u001b[0;36mextract_rest_apis_from_file_with_groq\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124mAnalyze this Python file and identify all Django REST API functions or classes. Only return the functions that are REST API endpoints. Only return entire implemenation of the function including function signature and content. \u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124mDo not include any text before or after the JSON.\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Lower temperature for more consistent JSON\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_TOKENS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOP_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTREAM\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     response \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# print(f\"response: {response}\")\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Try to extract JSON from the response\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/groq/resources/chat/completions.py:368\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    230\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    231\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch_settings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/groq/_base_client.py:1232\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1220\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1228\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1229\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1230\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1231\u001b[0m     )\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/groq/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1019\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/duct_env/.duct_env/lib/python3.9/site-packages/groq/_base_client.py:1060\u001b[0m, in \u001b[0;36mSyncAPIClient._sleep_for_retry\u001b[0;34m(self, retries_taken, max_retries, options, response)\u001b[0m\n\u001b[1;32m   1057\u001b[0m timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_retry_timeout(remaining_retries, options, response\u001b[38;5;241m.\u001b[39mheaders \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1058\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[0;32m-> 1060\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main execution function for notebook\n",
    "\"\"\"Analyze Django project and generate Dafny specifications\"\"\"\n",
    "\n",
    "#print(f\"Analyzing Django project at: {django_project_path}\")\n",
    "\n",
    "# Find all Python files\n",
    "django_files = find_django_files(DJANGO_PROJECT_PATH)\n",
    "print(f\"Found {len(django_files)} Python files\")\n",
    "\n",
    "# Extract REST APIs\n",
    "all_apis = []\n",
    "for file_path in tqdm(django_files, desc=\"Analyzing files\"):\n",
    "    apis = extract_rest_apis_from_file_with_groq(file_path)\n",
    "    all_apis.extend(apis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f967344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'GraphQLView',\n",
       "  'http_method': 'UNKNOWN',\n",
       "  'description': 'GraphQL API endpoint for handling GraphQL queries.',\n",
       "  'content_django': 'GraphQLView.as_view(backend=backend, schema=schema)',\n",
       "  'content_dafny': '// Dafny function specification for GraphQLView\\n// This function handles GraphQL queries and mutations.\\nmethod GraphQLView(backend: DatabaseBackend, schema: GraphQLSchema) returns (response: HttpResponse)\\n    requires backend != null;\\n    requires schema != null;\\n    ensures response != null;',\n",
       "  'file_path': '/Users/ryanmarr/Documents/saleor/saleor/urls.py'},\n",
       " {'name': 'digital_product',\n",
       "  'http_method': 'GET',\n",
       "  'description': 'Handles requests for digital product downloads.',\n",
       "  'content_django': 'def digital_product(request, token):\\n    # Implementation details would be here\\n    pass',\n",
       "  'content_dafny': '// Dafny function specification for digital_product\\n// This function retrieves a digital product based on the provided token.\\nmethod digital_product(request: HttpRequest, token: str) returns (response: HttpResponse)\\n    requires request != null;\\n    requires token != null;\\n    ensures response != null;',\n",
       "  'file_path': '/Users/ryanmarr/Documents/saleor/saleor/urls.py'},\n",
       " {'name': 'handle_plugin_per_channel_webhook',\n",
       "  'http_method': 'POST',\n",
       "  'description': 'Handles webhook requests for plugins per channel.',\n",
       "  'content_django': 'def handle_plugin_per_channel_webhook(request, channel_slug, plugin_id):\\n    # Implementation details would be here\\n    pass',\n",
       "  'content_dafny': '// Dafny function specification for handle_plugin_per_channel_webhook\\n// This function processes webhook requests for a specific plugin in a channel.\\nmethod handle_plugin_per_channel_webhook(request: HttpRequest, channel_slug: str, plugin_id: str) returns (response: HttpResponse)\\n    requires request != null;\\n    requires channel_slug != null;\\n    requires plugin_id != null;\\n    ensures response != null;',\n",
       "  'file_path': '/Users/ryanmarr/Documents/saleor/saleor/urls.py'},\n",
       " {'name': 'handle_global_plugin_webhook',\n",
       "  'http_method': 'POST',\n",
       "  'description': 'Handles global webhook requests for plugins.',\n",
       "  'content_django': 'def handle_global_plugin_webhook(request, plugin_id):\\n    # Implementation details would be here\\n    pass',\n",
       "  'content_dafny': '// Dafny function specification for handle_global_plugin_webhook\\n// This function processes global webhook requests for a specific plugin.\\nmethod handle_global_plugin_webhook(request: HttpRequest, plugin_id: str) returns (response: HttpResponse)\\n    requires request != null;\\n    requires plugin_id != null;\\n    ensures response != null;',\n",
       "  'file_path': '/Users/ryanmarr/Documents/saleor/saleor/urls.py'},\n",
       " {'name': 'handle_plugin_webhook',\n",
       "  'http_method': 'POST',\n",
       "  'description': 'Handles webhook requests for plugins.',\n",
       "  'content_django': 'def handle_plugin_webhook(request, plugin_id):\\n    # Implementation details would be here\\n    pass',\n",
       "  'content_dafny': '// Dafny function specification for handle_plugin_webhook\\n// This function processes webhook requests for a specific plugin.\\nmethod handle_plugin_webhook(request: HttpRequest, plugin_id: str) returns (response: HttpResponse)\\n    requires request != null;\\n    requires plugin_id != null;\\n    ensures response != null;',\n",
       "  'file_path': '/Users/ryanmarr/Documents/saleor/saleor/urls.py'},\n",
       " {'name': 'handle_thumbnail',\n",
       "  'http_method': 'GET',\n",
       "  'description': 'Handles requests for generating thumbnails.',\n",
       "  'content_django': 'def handle_thumbnail(request, instance_id, size, format):\\n    # Implementation details would be here\\n    pass',\n",
       "  'content_dafny': '// Dafny function specification for handle_thumbnail\\n// This function generates a thumbnail based on the provided parameters.\\nmethod handle_thumbnail(request: HttpRequest, instance_id: str, size: int, format: str) returns (response: HttpResponse)\\n    requires request != null;\\n    requires instance_id != null;\\n    requires size >= 0;\\n    ensures response != null;',\n",
       "  'file_path': '/Users/ryanmarr/Documents/saleor/saleor/urls.py'},\n",
       " {'name': 'jwks',\n",
       "  'http_method': 'GET',\n",
       "  'description': 'Serves the JSON Web Key Set (JWKS) for authentication.',\n",
       "  'content_django': 'def jwks(request):\\n    # Implementation details would be here\\n    pass',\n",
       "  'content_dafny': '// Dafny function specification for jwks\\n// This function retrieves and serves the JWKS for authentication.\\nmethod jwks(request: HttpRequest) returns (response: HttpResponse)\\n    requires request != null;\\n    ensures response != null;',\n",
       "  'file_path': '/Users/ryanmarr/Documents/saleor/saleor/urls.py'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249bbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_full_api_info(apis: List[Dict[str, Any]]):\n",
    "    \"\"\"Display complete API information with full Django code and Dafny specs\"\"\"\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(\"COMPLETE DJANGO REST API ANALYSIS\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Total APIs found: {len(apis)}\")\n",
    "    print()\n",
    "    \n",
    "    # Group by file path\n",
    "    files = {}\n",
    "    for api in apis:\n",
    "        file_path = api.get('file_path', 'Unknown')\n",
    "        if file_path not in files:\n",
    "            files[file_path] = []\n",
    "        files[file_path].append(api)\n",
    "    \n",
    "    # Display by file\n",
    "    for file_path, file_apis in files.items():\n",
    "        print(f\"📁 FILE: {file_path}\")\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"APIs found: {len(file_apis)}\")\n",
    "        print()\n",
    "        \n",
    "        for i, api in enumerate(file_apis, 1):\n",
    "            print(f\"🔗 API #{i}: {api.get('name', 'Unknown')}\")\n",
    "            print(f\"   Method: {api.get('http_method', 'UNKNOWN')}\")\n",
    "            print(f\"   Description: {api.get('description', 'No description')}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"📝 DJANGO CODE:\")\n",
    "            print(\"-\" * 50)\n",
    "            django_code = api.get('content_django', 'No Django code available')\n",
    "            print(django_code)\n",
    "            print()\n",
    "            \n",
    "            print(\"🔬 DAFNY SPECIFICATION:\")\n",
    "            print(\"-\" * 50)\n",
    "            dafny_spec = api.get('content_dafny', 'No Dafny specification available')\n",
    "            print(dafny_spec)\n",
    "            print()\n",
    "            \n",
    "            print(\"─\" * 100)\n",
    "            print()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"=\" * 100)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # HTTP method distribution\n",
    "    methods = {}\n",
    "    for api in apis:\n",
    "        method = api.get('http_method', 'UNKNOWN')\n",
    "        methods[method] = methods.get(method, 0) + 1\n",
    "    \n",
    "    print(\"HTTP Methods:\")\n",
    "    for method, count in sorted(methods.items()):\n",
    "        print(f\"  {method}: {count}\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Files analyzed: {len(files)}\")\n",
    "    print(f\"Total APIs: {len(apis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23afccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_full_api_info(all_apis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".duct_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
