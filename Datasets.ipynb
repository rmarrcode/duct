{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2978067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "DJANGO_PROJECT_PATH = \"/Users/ryanmarr/Documents/saleor\"\n",
    "MODEL_NAME = \"deepseek-r1-distill-llama-70b\"\n",
    "MAX_TOKENS = 2048\n",
    "TEMPERATURE = 0.1\n",
    "TOP_P = 1\n",
    "STREAM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14418da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq client setup\n",
    "client = Groq(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa98c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_django_files(directory: str) -> List[str]:\n",
    "    \"\"\"Perform DFS to find all Python files in Django project\"\"\"\n",
    "    django_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Skip common directories that don't contain Django code\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', 'env', '.git']]\n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                django_files.append(file_path)\n",
    "    \n",
    "    return django_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d07a2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rest_apis_from_file_with_groq(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Use Groq to analyze file content and find REST APIs\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()  \n",
    "        \n",
    "        # Skip files that don't contain common Django/API keywords\n",
    "        if not any(keyword in content.lower() for keyword in ['api', 'view', 'rest', 'http', 'request', 'response', 'serializer']):\n",
    "            return []\n",
    "\n",
    "        # if 'urls.py' in file_path:\n",
    "        #     return []\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Analyze this Python file and identify all Django REST API functions or classes. Only return the functions that are REST API endpoints. Only return entire implemenation of the function including function signature and content. \n",
    "        \n",
    "        File: {file_path}\n",
    "        \n",
    "        Look for:\n",
    "        1. Functions that handle HTTP methods (GET, POST, PUT, DELETE, PATCH)\n",
    "        2. Functions that process requests and return responses\n",
    "        3. Any other REST API endpoints\n",
    "        \n",
    "        File content:\n",
    "        {content}  # First 4000 chars for analysis\n",
    "        \n",
    "        IMPORTANT: Return ONLY valid JSON with this exact structure:\n",
    "        {{\n",
    "            \"apis\": [\n",
    "                {{\n",
    "                    \"name\": \"function_or_class_name\",\n",
    "                    \"http_method\": \"GET|POST|PUT|DELETE|PATCH|UNKNOWN\",\n",
    "                    \"description\": \"Brief description of what this API does\",\n",
    "                    \"content_django\": actual function and entire implementation funtion include function signature and content,\n",
    "                    \"content_dafny\": Based on the django function, create a Dafny function specification with preconditions and postconditions assume db schema exists as a dafny type\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \n",
    "        If no REST APIs are found, return: {{\"apis\": []}}\n",
    "        Do not include any text before or after the JSON.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                temperature=TEMPERATURE,  # Lower temperature for more consistent JSON\n",
    "                max_tokens=MAX_TOKENS,\n",
    "                top_p=TOP_P,\n",
    "                stream=STREAM\n",
    "            )\n",
    "            \n",
    "            response = completion.choices[0].message.content.strip()\n",
    "            # print(f\"response: {response}\")\n",
    "            # Try to extract JSON from the response\n",
    "            json_match = re.search(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(0)\n",
    "                try:\n",
    "                    result = json.loads(json_str)\n",
    "                    for api in result.get('apis', []):\n",
    "                        api['file_path'] = file_path\n",
    "                    return result.get('apis', [])\n",
    "                    # print(f'result: {result}')\n",
    "                    # apis = []\n",
    "                    \n",
    "                    # for api_info in result.get('apis', []):\n",
    "                    #     apis.append({\n",
    "                    #         'name': api_info.get('name', 'unknown'),\n",
    "                    #         'file': file_path,\n",
    "                    #         'content': content,\n",
    "                    #         'line': api_info.get('line_number', 1),\n",
    "                    #         'type': api_info.get('type', 'function'),\n",
    "                    #         'http_method': api_info.get('http_method', 'UNKNOWN'),\n",
    "                    #         'description': api_info.get('description', '')\n",
    "                    #     })\n",
    "                    \n",
    "                    # return apis\n",
    "                    \n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to parse JSON from response for {file_path}\")\n",
    "                    print(f\"Response: {response}\")\n",
    "                    print(f\"json_match: {json_match}\")\n",
    "                    return []\n",
    "            else:\n",
    "                print(f\"No JSON found in response for {file_path}\")\n",
    "                print(f\"Response: {response}\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error calling Groq API for {file_path}: {e}\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4045 Python files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 4/4045 [00:01<28:57,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/settings.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 10782, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   0%|          | 17/4045 [01:05<4:59:36,  4.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/payloads.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 13265, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/event_types.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 9046, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   1%|          | 44/4045 [03:46<7:59:40,  7.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/transport/asynchronous/transport.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 8290, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 78/4045 [10:43<9:47:48,  8.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/test_webhook_payloads.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 27405, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 81/4045 [11:53<16:36:37, 15.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/test_tasks.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 9361, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 91/4045 [13:23<8:45:36,  7.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/response_schemas/test_transaction.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 9200, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 96/4045 [14:04<8:31:43,  7.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/response_schemas/test_payment.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 6843, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   2%|▏         | 100/4045 [15:10<13:58:17, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_taxes.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 14884, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   3%|▎         | 104/4045 [15:21<7:29:29,  6.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Groq API for /Users/ryanmarr/Documents/saleor/saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_subscription.py: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01k1p9jeq1eprawa9nne146kdc` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 28295, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing files:   3%|▎         | 110/4045 [16:19<8:14:43,  7.54s/it] "
     ]
    }
   ],
   "source": [
    "# Main execution function for notebook\n",
    "\"\"\"Analyze Django project and generate Dafny specifications\"\"\"\n",
    "\n",
    "#print(f\"Analyzing Django project at: {django_project_path}\")\n",
    "\n",
    "# Find all Python files\n",
    "django_files = find_django_files(DJANGO_PROJECT_PATH)\n",
    "print(f\"Found {len(django_files)} Python files\")\n",
    "\n",
    "# Extract REST APIs\n",
    "all_apis = []\n",
    "for file_path in tqdm(django_files, desc=\"Analyzing files\"):\n",
    "    apis = extract_rest_apis_from_file_with_groq(file_path)\n",
    "    all_apis.extend(apis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f967344",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249bbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_full_api_info(apis: List[Dict[str, Any]]):\n",
    "    \"\"\"Display complete API information with full Django code and Dafny specs\"\"\"\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(\"COMPLETE DJANGO REST API ANALYSIS\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Total APIs found: {len(apis)}\")\n",
    "    print()\n",
    "    \n",
    "    # Group by file path\n",
    "    files = {}\n",
    "    for api in apis:\n",
    "        file_path = api.get('file_path', 'Unknown')\n",
    "        if file_path not in files:\n",
    "            files[file_path] = []\n",
    "        files[file_path].append(api)\n",
    "    \n",
    "    # Display by file\n",
    "    for file_path, file_apis in files.items():\n",
    "        print(f\"📁 FILE: {file_path}\")\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"APIs found: {len(file_apis)}\")\n",
    "        print()\n",
    "        \n",
    "        for i, api in enumerate(file_apis, 1):\n",
    "            print(f\"🔗 API #{i}: {api.get('name', 'Unknown')}\")\n",
    "            print(f\"   Method: {api.get('http_method', 'UNKNOWN')}\")\n",
    "            print(f\"   Description: {api.get('description', 'No description')}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"📝 DJANGO CODE:\")\n",
    "            print(\"-\" * 50)\n",
    "            django_code = api.get('content_django', 'No Django code available')\n",
    "            print(django_code)\n",
    "            print()\n",
    "            \n",
    "            print(\"🔬 DAFNY SPECIFICATION:\")\n",
    "            print(\"-\" * 50)\n",
    "            dafny_spec = api.get('content_dafny', 'No Dafny specification available')\n",
    "            print(dafny_spec)\n",
    "            print()\n",
    "            \n",
    "            print(\"─\" * 100)\n",
    "            print()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"=\" * 100)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # HTTP method distribution\n",
    "    methods = {}\n",
    "    for api in apis:\n",
    "        method = api.get('http_method', 'UNKNOWN')\n",
    "        methods[method] = methods.get(method, 0) + 1\n",
    "    \n",
    "    print(\"HTTP Methods:\")\n",
    "    for method, count in sorted(methods.items()):\n",
    "        print(f\"  {method}: {count}\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Files analyzed: {len(files)}\")\n",
    "    print(f\"Total APIs: {len(apis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23afccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_full_api_info(all_apis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".duct_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
